{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>B42</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C148</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass  \\\n",
       "0              1         0       3   \n",
       "1              2         1       1   \n",
       "2              3         1       3   \n",
       "3              4         1       1   \n",
       "4              5         0       3   \n",
       "..           ...       ...     ...   \n",
       "886          887         0       2   \n",
       "887          888         1       1   \n",
       "888          889         0       3   \n",
       "889          890         1       1   \n",
       "890          891         0       3   \n",
       "\n",
       "                                                  Name     Sex   Age  SibSp  \\\n",
       "0                              Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                               Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                             Allen, Mr. William Henry    male  35.0      0   \n",
       "..                                                 ...     ...   ...    ...   \n",
       "886                              Montvila, Rev. Juozas    male  27.0      0   \n",
       "887                       Graham, Miss. Margaret Edith  female  19.0      0   \n",
       "888           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1   \n",
       "889                              Behr, Mr. Karl Howell    male  26.0      0   \n",
       "890                                Dooley, Mr. Patrick    male  32.0      0   \n",
       "\n",
       "     Parch            Ticket     Fare Cabin Embarked  \n",
       "0        0         A/5 21171   7.2500   NaN        S  \n",
       "1        0          PC 17599  71.2833   C85        C  \n",
       "2        0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3        0            113803  53.1000  C123        S  \n",
       "4        0            373450   8.0500   NaN        S  \n",
       "..     ...               ...      ...   ...      ...  \n",
       "886      0            211536  13.0000   NaN        S  \n",
       "887      0            112053  30.0000   B42        S  \n",
       "888      2        W./C. 6607  23.4500   NaN        S  \n",
       "889      0            111369  30.0000  C148        C  \n",
       "890      0            370376   7.7500   NaN        Q  \n",
       "\n",
       "[891 rows x 12 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(os.path.join('data', \"train.csv\"))\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' def disembarque(x: int) -> str:\\n    if x == 0:\\n        return \"S\"\\n    elif x == 1:\\n        return \"C\"\\n    else:\\n        return \"Q\" '"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def substitute_sex(x: str) -> int:\n",
    "    return int(x != \"male\")\n",
    "\n",
    "\n",
    "def stone_the_adulters(x: int) -> str: # denormalizing function\n",
    "    return \"male\" if x == 0 else \"female\"\n",
    "\n",
    "\"\"\" def substitute_embarked(x: str) -> int:\n",
    "    if x == \"S\":\n",
    "        return 0\n",
    "    elif x == \"C\":\n",
    "        return 1\n",
    "    else:\n",
    "        return 2 \"\"\"\n",
    "\n",
    "\"\"\" def disembarque(x: int) -> str:\n",
    "    if x == 0:\n",
    "        return \"S\"\n",
    "    elif x == 1:\n",
    "        return \"C\"\n",
    "    else:\n",
    "        return \"Q\" \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.drop(columns=['PassengerId', 'Name', 'Ticket', 'Fare', 'Cabin', 'Embarked'])\n",
    "train_df = train_df.dropna()\n",
    "\n",
    "\n",
    "train_df['Sex'] = train_df['Sex'].apply(substitute_sex)\n",
    "#train_df['Embarked'] = train_df['Embarked'].apply(substitute_embarked)\n",
    "\n",
    "\n",
    "mean = train_df['Age'].mean()\n",
    "std = train_df['Age'].std()\n",
    "train_df['Age'] = (train_df['Age'] - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['bias'] = [1 for x in range((train_df.shape[0]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>bias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.530005</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.571430</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.254646</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.364911</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.364911</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.640270</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.185807</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.736524</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.254646</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.158392</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>714 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survived  Pclass  Sex       Age  SibSp  Parch  bias\n",
       "0           0       3    0 -0.530005      1      0     1\n",
       "1           1       1    1  0.571430      1      0     1\n",
       "2           1       3    1 -0.254646      0      0     1\n",
       "3           1       1    1  0.364911      1      0     1\n",
       "4           0       3    0  0.364911      0      0     1\n",
       "..        ...     ...  ...       ...    ...    ...   ...\n",
       "885         0       3    1  0.640270      0      5     1\n",
       "886         0       2    0 -0.185807      0      0     1\n",
       "887         1       1    1 -0.736524      0      0     1\n",
       "889         1       1    0 -0.254646      0      0     1\n",
       "890         0       3    0  0.158392      0      0     1\n",
       "\n",
       "[714 rows x 7 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "\n",
    "X = train_df.drop(columns=['Survived'])\n",
    "y = train_df['Survived']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.values, y.values, test_size=0.15, random_state=69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((606, 6), (108, 6), (606,), (108,))"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSELoss(y_true: np.ndarray, y_pred: np.ndarray) -> np.float32:\n",
    "    y_true = y_true.flatten()\n",
    "    y_pred = y_pred.flatten()\n",
    "    return (1/len(y_true)) * np.sum((y_pred - y_true) ** 2)\n",
    "\n",
    "def accuracy_with_thresholding(y_true: np.ndarray, y_pred: np.ndarray, threshold = 0.5):\n",
    "    y_true = y_true.flatten()\n",
    "    y_pred = y_pred.flatten()\n",
    "    return np.sum(\n",
    "        y_true == (y_pred > threshold).astype(np.int32)\n",
    "    ) / len(y_true)\n",
    "    \n",
    "def precision(y_true: np.ndarray, y_pred: np.ndarray, threshold=0.5) -> float:\n",
    "    y_pred_bin = (y_pred > threshold).astype(np.int32)\n",
    "    true_positives = np.sum((y_pred_bin == 1) & (y_true == 1))\n",
    "    predicted_positives = np.sum(y_pred_bin == 1)\n",
    "    if predicted_positives == 0:\n",
    "        return 0.0\n",
    "    return true_positives / predicted_positives\n",
    "\n",
    "def recall(y_true: np.ndarray, y_pred: np.ndarray, threshold=0.5) -> float:\n",
    "    y_pred_bin = (y_pred > threshold).astype(np.int32)\n",
    "    true_positives = np.sum((y_pred_bin == 1) & (y_true == 1))\n",
    "    actual_positives = np.sum(y_true == 1)\n",
    "    if actual_positives == 0:\n",
    "        return 0.0\n",
    "    return true_positives / actual_positives\n",
    "\n",
    "def f1_score(y_true: np.ndarray, y_pred: np.ndarray, threshold=0.5) -> float:\n",
    "    p = precision(y_true, y_pred, threshold)\n",
    "    r = recall(y_true, y_pred, threshold)\n",
    "    if p + r == 0:\n",
    "        return 0.0\n",
    "    return 2 * (p * r) / (p + r)\n",
    " \n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1/(1 + np.exp(-z))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full batch Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "GridSearchCV.__init__() missing 2 required positional arguments: 'estimator' and 'param_grid'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[89], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m reg \u001b[38;5;241m=\u001b[39m LinearRegression()\n\u001b[1;32m----> 3\u001b[0m \u001b[43mGridSearchCV\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy_with_thresholding(y_test,\u001b[38;5;250m \u001b[39my_pred)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrecision: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprecision(y_test,\u001b[38;5;250m \u001b[39my_pred)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: GridSearchCV.__init__() missing 2 required positional arguments: 'estimator' and 'param_grid'"
     ]
    }
   ],
   "source": [
    "np.random.seed(69)\n",
    "W = np.random.rand(6).reshape(6,1)\n",
    "learning_rate = 0.000005\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n",
      "0.01\n",
      "0.001\n",
      "0.0001\n",
      "1e-05\n",
      "1e-06\n",
      "1e-07\n",
      "1e-08\n",
      "1e-09\n"
     ]
    }
   ],
   "source": [
    "for learning_rate in [1/(10**x) for x in range(1, 10)]:\n",
    "    print(learning_rate)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate_results = []\n",
    "for learning_rate in [1/(10**x) for x in range(1, 10)]:\n",
    "    W = np.random.rand(6).reshape(6,1)\n",
    "    epochs = 10000\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        y_pred = sigmoid(np.matmul(X_train, W))\n",
    "        train_loss = MSELoss(y_train, y_pred)\n",
    "        W = W - learning_rate * np.matmul(X_train.T, (y_pred - y_train.reshape(-1,1)) * (y_pred * (1-y_pred)))\n",
    "        \n",
    "        y_pred_val = sigmoid(np.matmul(X_test, W))\n",
    "        validation_loss = MSELoss(y_test, y_pred_val)\n",
    "        validation_accuracy = accuracy_with_thresholding(y_test, y_pred_val)\n",
    "        val_precision = precision(y_test, y_pred_val)\n",
    "        val_recall = recall(y_test, y_pred_val)\n",
    "        f1 = f1_score(y_test, y_pred_val)\n",
    "    learning_rate_results.append({\n",
    "        'learning_rate': learning_rate,\n",
    "        'train_loss': train_loss,\n",
    "        'validation_loss': validation_loss,\n",
    "        'validation_accuracy': validation_accuracy\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'learning_rate': 0.1, 'train_loss': 0.1669130500725618, 'validation_loss': 0.16523529668542605, 'validation_accuracy': 0.7777777777777778}, {'learning_rate': 0.01, 'train_loss': 0.14255229843172543, 'validation_loss': 0.1255399883043819, 'validation_accuracy': 0.8055555555555556}, {'learning_rate': 0.001, 'train_loss': 0.14255231812661837, 'validation_loss': 0.1255438697239405, 'validation_accuracy': 0.8055555555555556}, {'learning_rate': 0.0001, 'train_loss': 0.14324526833313717, 'validation_loss': 0.1272906151902408, 'validation_accuracy': 0.8055555555555556}, {'learning_rate': 1e-05, 'train_loss': 0.16601847807764095, 'validation_loss': 0.16171647948933615, 'validation_accuracy': 0.7870370370370371}, {'learning_rate': 1e-06, 'train_loss': 0.22778928012128866, 'validation_loss': 0.2307668656774978, 'validation_accuracy': 0.6111111111111112}, {'learning_rate': 1e-07, 'train_loss': 0.4588072347169639, 'validation_loss': 0.40255447053164406, 'validation_accuracy': 0.4722222222222222}, {'learning_rate': 1e-08, 'train_loss': 0.5428472778561663, 'validation_loss': 0.47195447642530175, 'validation_accuracy': 0.4722222222222222}, {'learning_rate': 1e-09, 'train_loss': 0.47981046973577557, 'validation_loss': 0.4178073486338856, 'validation_accuracy': 0.4722222222222222}]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>validation_loss</th>\n",
       "      <th>validation_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000e-01</td>\n",
       "      <td>0.166913</td>\n",
       "      <td>0.165235</td>\n",
       "      <td>0.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000e-02</td>\n",
       "      <td>0.142552</td>\n",
       "      <td>0.125540</td>\n",
       "      <td>0.805556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000000e-03</td>\n",
       "      <td>0.142552</td>\n",
       "      <td>0.125544</td>\n",
       "      <td>0.805556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000000e-04</td>\n",
       "      <td>0.143245</td>\n",
       "      <td>0.127291</td>\n",
       "      <td>0.805556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000000e-05</td>\n",
       "      <td>0.166018</td>\n",
       "      <td>0.161716</td>\n",
       "      <td>0.787037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.000000e-06</td>\n",
       "      <td>0.227789</td>\n",
       "      <td>0.230767</td>\n",
       "      <td>0.611111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>0.458807</td>\n",
       "      <td>0.402554</td>\n",
       "      <td>0.472222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>0.542847</td>\n",
       "      <td>0.471954</td>\n",
       "      <td>0.472222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.000000e-09</td>\n",
       "      <td>0.479810</td>\n",
       "      <td>0.417807</td>\n",
       "      <td>0.472222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   learning_rate  train_loss  validation_loss  validation_accuracy\n",
       "0   1.000000e-01    0.166913         0.165235             0.777778\n",
       "1   1.000000e-02    0.142552         0.125540             0.805556\n",
       "2   1.000000e-03    0.142552         0.125544             0.805556\n",
       "3   1.000000e-04    0.143245         0.127291             0.805556\n",
       "4   1.000000e-05    0.166018         0.161716             0.787037\n",
       "5   1.000000e-06    0.227789         0.230767             0.611111\n",
       "6   1.000000e-07    0.458807         0.402554             0.472222\n",
       "7   1.000000e-08    0.542847         0.471954             0.472222\n",
       "8   1.000000e-09    0.479810         0.417807             0.472222"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(learning_rate_results)\n",
    "results_df = pd.DataFrame(learning_rate_results, columns=['learning_rate', 'train_loss', 'validation_loss', 'validation_accuracy'])\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: title={'center': 'Validation Accuracy vs Learning Rate'}, xlabel='learning_rate'>"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAHpCAYAAABQsTz+AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAWFNJREFUeJzt3Xtcjvf/B/DX3enuqFAqLXKIsIhaKXOaLIZljBy2CDHk1JhlU40R5hATxpDjhNlsYzk0fWeKiOZ8lnORQ1EU3Z/fH37dc+su3ZUud17Px+N6bF3X57qu9+e+7tyvrutzXbdMCCFAREREJBEdqQsgIiKiNxvDCBEREUmKYYSIiIgkxTBCREREkmIYISIiIkkxjBAREZGkGEaIiIhIUgwjREREJCmGESIiIpIUwwhVuNTUVMhkMkRHRyvnhYeHQyaTlWh9mUyG8PDwcq2pXbt2aNeuXbluk0hqfF+TtmAYoWJ9+OGHMDY2xoMHD4ps079/fxgYGODOnTsVWJnmTp48ifDwcKSmpkpdilrbt2+HTCZDzZo1oVAopC6H/l98fDxkMhk2b94sdSlaxcHBATKZTDmZmJjA3d0dq1evLvU2t2/fXu5/iNDrgWGEitW/f388evQIv/zyi9rlOTk52Lp1Kzp16oTq1auXej9ff/01Hj16VOr1S+LkyZP45ptv1IaRnTt3YufOna90/y+zbt06ODg44ObNm/jrr78krYUqB6nf1y4uLlizZg3WrFmD8PBwZGZmYsCAAVi2bFmptrd9+3Z888035VwlvQ4YRqhYH374IczMzLB+/Xq1y7du3Yrs7Gz079+/TPvR09ODoaFhmbZRFgYGBjAwMJBs/9nZ2di6dSuCg4PRvHlzrFu3TrJaXiY7O1vqEt5ICoUCjx8/1mgdqd/XdnZ2+OSTT/DJJ59gwoQJ+Oeff2Bqaop58+ZJVhO9nhhGqFhGRkbo0aMH4uLicOvWrULL169fDzMzM3z44Ye4e/cuxo8fD2dnZ5iamqJKlSro3Lkz/v3335fuR92YkdzcXIwbNw5WVlbKfVy7dq3QupcvX8aIESPQsGFDGBkZoXr16ujVq5fKGZDo6Gj06tULANC+fXvlqeP4+HgA6q+t37p1C4MHD4a1tTUMDQ3RrFkzrFq1SqVNwfiX2bNnY+nSpahXrx7kcjneeecdHDx48KX9LvDLL7/g0aNH6NWrF/r06YMtW7ao/eB5/PgxwsPD0aBBAxgaGsLW1hY9evTAhQsXlG0UCgXmz58PZ2dnGBoawsrKCp06dcKhQ4dUan5+zE6BF8fjFByXkydPol+/fqhatSreffddAMDRo0cxcOBA1K1bF4aGhrCxscGgQYPUXq67fv06Bg8ejJo1a0Iul6NOnToYPnw48vLycPHiRchkMrUfUAkJCZDJZPjpp5/Uvm7p6enQ09NT+9fymTNnIJPJsHDhQgDAkydP8M0338DR0RGGhoaoXr063n33XezatUvttjV1//59jB07Fvb29pDL5ahfvz5mzpxZ6JLb7Nmz4eXlherVq8PIyAiurq5qLwHJZDIEBQVh3bp1aNKkCeRyOWJjYxEdHQ2ZTIZ9+/YhODgYVlZWMDExwUcffYTbt2+rbOPF93XBJaeNGzdi2rRpeOutt2BoaIgOHTrg/PnzhWqIiopC3bp1YWRkBHd3d+zdu7dM41CsrKzg5OSk8n4FgL1796JXr16oVasW5HI57O3tMW7cOJWzpQMHDkRUVJTytSmYCigUCkRGRqJJkyYwNDSEtbU1hg0bhnv37pWqVqpYelIXQK+//v37Y9WqVdi4cSOCgoKU8+/evYsdO3agb9++MDIywokTJ/Drr7+iV69eqFOnDtLT0/HDDz+gbdu2OHnyJGrWrKnRfocMGYK1a9eiX79+8PLywl9//YUuXboUanfw4EEkJCSgT58+eOutt5CamorFixejXbt2OHnyJIyNjdGmTRuMHj0aCxYswKRJk9CoUSMAUP73RY8ePUK7du1w/vx5BAUFoU6dOti0aRMGDhyI+/fvY8yYMSrt169fjwcPHmDYsGGQyWSYNWsWevTogYsXL0JfX/+lfV23bh3at28PGxsb9OnTB19++SV+//13ZYACgPz8fHTt2hVxcXHo06cPxowZgwcPHmDXrl04fvw46tWrBwAYPHgwoqOj0blzZwwZMgRPnz7F3r17sX//fri5uZX49X9er1694OjoiOnTp0MIAQDYtWsXLl68iICAANjY2ODEiRNYunQpTpw4gf379ys/KG7cuAF3d3fcv38fQ4cOhZOTE65fv47NmzcjJycHdevWRatWrbBu3TqMGzeu0OtiZmYGX19ftXVZW1ujbdu22LhxI8LCwlSWxcTEQFdXV/kahoeHIyIiAkOGDIG7uzuysrJw6NAhHD58GB07dizV61IgJycHbdu2xfXr1zFs2DDUqlULCQkJCAkJwc2bNxEZGalsO3/+fHz44Yfo378/8vLysGHDBvTq1Qt//PFHoff3X3/9pfy9s7S0hIODA1JSUgAAo0aNQtWqVREWFobU1FRERkYiKCgIMTExL613xowZ0NHRwfjx45GZmYlZs2ahf//+OHDggLLN4sWLERQUhNatW2PcuHFITU1F9+7dUbVqVbz11lulep2ePn2Ka9euoWrVqirzN23ahJycHAwfPhzVq1dHUlISvv/+e1y7dg2bNm0CAAwbNgw3btzArl27sGbNmkLbHjZsGKKjoxEQEIDRo0fj0qVLWLhwIY4cOYJ9+/aV6PeQJCSIXuLp06fC1tZWeHp6qsxfsmSJACB27NghhBDi8ePHIj8/X6XNpUuXhFwuF1OmTFGZB0CsXLlSOS8sLEw8/3ZMSUkRAMSIESNUttevXz8BQISFhSnn5eTkFKo5MTFRABCrV69Wztu0aZMAIPbs2VOofdu2bUXbtm2VP0dGRgoAYu3atcp5eXl5wtPTU5iamoqsrCyVvlSvXl3cvXtX2Xbr1q0CgPj9998L7etF6enpQk9PTyxbtkw5z8vLS/j6+qq0W7FihQAg5s6dW2gbCoVCCCHEX3/9JQCI0aNHF9lG3etf4MXXtuC49O3bt1Bbda/7Tz/9JACIv//+WznP399f6OjoiIMHDxZZ0w8//CAAiFOnTimX5eXlCUtLSzFgwIBC6z2vYN1jx46pzG/cuLF47733lD83a9ZMdOnSpdhtqbNnzx4BQGzatKnINlOnThUmJibi7NmzKvO//PJLoaurK65cuaKc9+LrlpeXJ95++22VWoV4dix0dHTEiRMnVOavXLlSABDe3t7K108IIcaNGyd0dXXF/fv3lfNefF8X9KVRo0YiNzdXOX/+/Pkqr2Fubq6oXr26eOedd8STJ0+U7aKjowUAlW0WpXbt2uL9998Xt2/fFrdv3xbHjh0Tn376qQAgRo4cqdJW3XspIiJCyGQycfnyZeW8kSNHCnUfW3v37hUAxLp161Tmx8bGqp1Prx9epqGX0tXVRZ8+fZCYmKhy6WP9+vWwtrZGhw4dAAByuRw6Os/eUvn5+bhz5w5MTU3RsGFDHD58WKN9bt++HQAwevRolfljx44t1NbIyEj5/0+ePMGdO3dQv359WFhYaLzf5/dvY2ODvn37Kufp6+tj9OjRePjwIf73v/+ptPfz81P5a69169YAgIsXL750Xxs2bICOjg569uypnNe3b1/8+eefKqeYf/75Z1haWmLUqFGFtlFwFuLnn3+GTCYrdJbg+Tal8dlnnxWa9/zr/vjxY2RkZKBly5YAoHzdFQoFfv31V3Tr1k3tWZmCmnr37g1DQ0OVsTI7duxARkYGPvnkk2Jr69GjB/T09FTOCBw/fhwnT56En5+fcp6FhQVOnDiBc+fOlaTLGtm0aRNat26NqlWrIiMjQzl5e3sjPz8ff//9t7Lt86/bvXv3kJmZidatW6t9r7Zt2xaNGzdWu8+hQ4eqHNPWrVsjPz8fly9ffmm9AQEBKmNJXny/Hjp0CHfu3EFgYCD09P47gd6/f/9CZzWKs3PnTlhZWcHKygrOzs5Ys2YNAgIC8N1336m0e/41yc7ORkZGBry8vCCEwJEjR166n02bNsHc3BwdO3ZUef1dXV1hamqKPXv2lLhmkgbDCJVIwQDVgoGs165dw969e9GnTx/o6uoCePbBM2/ePDg6OkIul8PS0hJWVlY4evQoMjMzNdrf5cuXoaOjo7z0UKBhw4aF2j569AihoaHKa/UF+71//77G+31+/46OjspwVaDgss6L/+DXqlVL5eeCf7BLcr167dq1cHd3x507d3D+/HmcP38ezZs3R15envIUNQBcuHABDRs2VPlweNGFCxdQs2ZNVKtW7aX71USdOnUKzbt79y7GjBkDa2trGBkZwcrKStmu4HW/ffs2srKy8Pbbbxe7fQsLC3Tr1k1loPS6detgZ2eH9957r9h1LS0t0aFDB2zcuFE5LyYmBnp6eujRo4dy3pQpU3D//n00aNAAzs7OmDBhAo4ePfryzpfAuXPnEBsbq/zgLZi8vb0BQGW81R9//IGWLVvC0NAQ1apVg5WVFRYvXqz2varudS9Qlvfcy9YteH/Xr19fpZ2enh4cHBxeuv0CHh4e2LVrF2JjYzF79mxYWFjg3r17hQbVXrlyBQMHDkS1atVgamoKKysrtG3bFgBK9Dt87tw5ZGZmokaNGoWOwcOHD9WOd6PXC8eMUIm4urrCyckJP/30EyZNmoSffvoJQgiVu2imT5+OyZMnY9CgQZg6dSqqVasGHR0djB079pU+N2PUqFFYuXIlxo4dC09PT5ibm0Mmk6FPnz4V9ryOgkD2IvH/4yuKcu7cOeVAV0dHx0LL161bh6FDh5a9wOcUdYYkPz+/yHWe/8u1QO/evZGQkIAJEybAxcUFpqamUCgU6NSpU6led39/f2zatAkJCQlwdnbGb7/9hhEjRhQKhOr06dMHAQEBSElJgYuLCzZu3IgOHTrA0tJS2aZNmza4cOECtm7dip07d+LHH3/EvHnzsGTJEgwZMkTjep+nUCjQsWNHfPHFF2qXN2jQAMCzgZoffvgh2rRpg0WLFsHW1hb6+vpYuXKl2jvW1L3uBUr7nivrupqwtLRUBjIfHx84OTmha9eumD9/PoKDgwE8e9917NgRd+/excSJE+Hk5AQTExNcv34dAwcOLNF7SaFQoEaNGkXehWZlZVV+naJXgmGESqx///6YPHkyjh49ivXr18PR0RHvvPOOcvnmzZvRvn17LF++XGW9+/fvq3wolETt2rWhUCiUZwMKnDlzplDbzZs3Y8CAAZgzZ45y3uPHj3H//n2VdppcpqhduzaOHj0KhUKh8mF4+vRp5fLysG7dOujr62PNmjWFPiD++ecfLFiwAFeuXEGtWrVQr149HDhwAE+ePClyMF69evWwY8cO3L17t8izIwV/Bb/4+pTk9H6Be/fuIS4uDt988w1CQ0OV81+8BGJlZYUqVarg+PHjL91mp06dYGVlhXXr1sHDwwM5OTn49NNPS1RP9+7dMWzYMOWlmrNnzyIkJKRQu2rVqiEgIAABAQF4+PAh2rRpg/Dw8DKHkXr16uHhw4fKD96i/PzzzzA0NMSOHTsgl8uV81euXFmm/Ze3gvf3+fPn0b59e+X8p0+fIjU1FU2bNi3Vdrt06YK2bdti+vTpGDZsGExMTHDs2DGcPXsWq1atgr+/v7KturucivodrlevHnbv3o1WrVoVG+Do9cXLNFRiBWdBQkNDkZKSUujZIrq6uoX+stq0aROuX7+u8b46d+4MAFiwYIHK/OfvSihuv99//32hv/RNTEwAFP4QVueDDz5AWlqayjiEp0+f4vvvv4epqanyFHJZrVu3Dq1bt4afnx8+/vhjlWnChAkAoLyttWfPnsjIyFDeqvq8gv737NkTQgi1t7oWtKlSpQosLS1VxjEAwKJFi0pcd0FwevF1f/H46OjooHv37vj999+Vtxarqwl4dgmgb9++2LhxI6Kjo+Hs7FziDz0LCwv4+Phg48aN2LBhAwwMDNC9e3eVNi/ecmxqaor69esjNze3RPsoTu/evZGYmIgdO3YUWnb//n08ffoUwLPXTSaTqbw3U1NT8euvv5a5hvLk5uaG6tWrY9myZcragWfv17LeKjtx4kTcuXNH+eAzde8lIQTmz59faN2ifod79+6N/Px8TJ06tdA6T58+LdHvPEmLZ0aoxOrUqQMvLy9s3boVAAqFka5du2LKlCkICAiAl5cXjh07hnXr1qFu3boa78vFxQV9+/bFokWLkJmZCS8vL8TFxal9FkLXrl2xZs0amJubo3HjxkhMTMTu3bsLPRHWxcUFurq6mDlzJjIzMyGXy/Hee++hRo0ahbY5dOhQ/PDDDxg4cCCSk5Ph4OCAzZs3Y9++fYiMjISZmZnGfXrRgQMHlLcOq2NnZ4cWLVpg3bp1mDhxIvz9/bF69WoEBwcjKSkJrVu3RnZ2Nnbv3o0RI0bA19cX7du3x6effooFCxbg3Llzyksme/fuRfv27ZX7GjJkCGbMmIEhQ4bAzc0Nf//9N86ePVvi2qtUqYI2bdpg1qxZePLkCezs7LBz505cunSpUNvp06dj586daNu2LYYOHYpGjRrh5s2b2LRpE/755x9YWFgo2/r7+2PBggXYs2cPZs6cqdHr6efnh08++QSLFi2Cj4+PynYBoHHjxmjXrh1cXV1RrVo1HDp0CJs3by7y9X/Rzz//rDwz9rwBAwZgwoQJ+O2339C1a1cMHDgQrq6uyM7OxrFjx7B582akpqbC0tISXbp0wdy5c9GpUyf069cPt27dQlRUFOrXr19u41fKg4GBAcLDwzFq1Ci899576N27N1JTUxEdHY169eqVaTB0586d8fbbb2Pu3LkYOXIknJycUK9ePYwfPx7Xr19HlSpV8PPPP6sNPa6urgCeDWz38fFRDq5v27Ythg0bhoiICKSkpOD999+Hvr4+zp07h02bNmH+/Pn4+OOPS10zVQApbuEh7RUVFSUACHd390LLHj9+LD7//HNha2srjIyMRKtWrURiYmKh2wtLcmuvEEI8evRIjB49WlSvXl2YmJiIbt26iatXrxa6/fTevXsiICBAWFpaClNTU+Hj4yNOnz4tateuXei20GXLlom6desKXV1dldt8X6xRiGe33BZs18DAQDg7Oxe6HbagL999912h1+PFOl80atQoAUBcuHChyDbh4eECgPj333+FEM9ugfzqq69EnTp1hL6+vrCxsREff/yxyjaePn0qvvvuO+Hk5CQMDAyElZWV6Ny5s0hOTla2ycnJEYMHDxbm5ubCzMxM9O7dW9y6davIW3tv375dqLZr166Jjz76SFhYWAhzc3PRq1cvcePGDbX9vnz5svD39xdWVlZCLpeLunXripEjR6rcXlqgSZMmQkdHR1y7dq3I10WdrKwsYWRkVOiW7ALffvutcHd3FxYWFsLIyEg4OTmJadOmiby8vGK3W3A7bFHT3r17hRBCPHjwQISEhIj69esLAwMDYWlpKby8vMTs2bNV9rF8+XLh6Ogo5HK5cHJyEitXrlT7/oeaW2CF+O/W3hdvlS6o8/lb14u6tffF25SLut17wYIFonbt2kIulwt3d3exb98+4erqKjp16lTsaybEs1t7i7qVuuAW4YL9nTx5Unh7ewtTU1NhaWkpAgMDxb///luopqdPn4pRo0YJKysrIZPJCr1mS5cuFa6ursLIyEiYmZkJZ2dn8cUXX4gbN268tF6SlkyIch6xRERUBs2bN0e1atUQFxcndSn0AoVCASsrK/To0aPU3y9DpA7HjBDRa+PQoUNISUlRGchI0nj8+HGhMUGrV6/G3bt3S/04eKKi8MwIEUnu+PHjSE5Oxpw5c5CRkYGLFy9K+sWJ9Ox7bMaNG4devXqhevXqOHz4MJYvX45GjRohOTlZ0i/go8qHA1iJSHKbN2/GlClT0LBhQ/z0008MIq8BBwcH2NvbY8GCBcpbxf39/TFjxgwGESp3PDNCREREkuKYESIiIpIUwwgRERFJSivGjCgUCty4cQNmZmZletgOERERVRwhBB48eICaNWsW+z1TWhFGbty4AXt7e6nLICIiolK4evUq3nrrrSKXa0UYKXj09tWrV1GlShWJqyEiIqKSyMrKgr29/Uu/QkMrwkjBpZkqVaowjBAREWmZlw2x4ABWIiIikhTDCBEREUmKYYSIiIgkpRVjRoiItI0QAk+fPkV+fr7UpRC9Mrq6utDT0yvzYzcYRoiIylleXh5u3ryJnJwcqUsheuWMjY1ha2tbpu8sYhghIipHCoUCly5dgq6uLmrWrAkDAwM+rJEqJSEE8vLycPv2bVy6dAmOjo7FPtisOAwjRETlKC8vDwqFAvb29jA2Npa6HKJXysjICPr6+rh8+TLy8vJK/Y3bHMBKRPQKlPYvRCJtUx7vdf62EBERkaQYRoiIiEhSDCNERFQuHBwcEBkZqfxZJpPh119/LbJ9amoqZDIZUlJSyrTf8toOSYcDWImIKojDl9sqbF+pM7pU2L6KcvPmTVStWrVctzlw4EDcv39fJeTY29vj5s2bsLS0LNd9UcVhGCEiolfCxsamQvajq6tbYft6XeXn50Mmk2ntwOlSVR0VFQUHBwcYGhrCw8MDSUlJxbaPjIxEw4YNYWRkBHt7e4wbNw6PHz8uVcFERFT+li5dipo1a0KhUKjM9/X1xaBBg3DhwgX4+vrC2toapqameOedd7B79+5it/niZZqkpCQ0b94choaGcHNzw5EjR1Ta5+fnY/DgwahTpw6MjIzQsGFDzJ8/X7k8PDwcq1atwtatWyGTySCTyRAfH6/2Ms3//vc/uLu7Qy6Xw9bWFl9++SWePn2qXN6uXTuMHj0aX3zxBapVqwYbGxuEh4eX+PWaO3cunJ2dYWJiAnt7e4wYMQIPHz5UabNv3z60a9cOxsbGqFq1Knx8fHDv3j0Az55HM2vWLNSvXx9yuRy1atXCtGnTAADx8fGQyWS4f/++clspKSmQyWRITU0FAERHR8PCwgK//fYbGjduDLlcjitXruDgwYPo2LEjLC0tYW5ujrZt2+Lw4cMqdd2/fx/Dhg2DtbU1DA0N8fbbb+OPP/5AdnY2qlSpgs2bN6u0//XXX2FiYoIHDx6U+PXRlMZnRmJiYhAcHIwlS5bAw8MDkZGR8PHxwZkzZ1CjRo1C7devX48vv/wSK1asgJeXF86ePYuBAwdCJpNh7ty55dKJN1VlPuXLvpWP1+FUPWmHXr16YdSoUdizZw86dOgAALh79y5iY2Oxfft2PHz4EB988AGmTZsGuVyO1atXo1u3bjhz5gxq1ar10u0/fPgQXbt2RceOHbF27VpcunQJY8aMUWmjUCjw1ltvYdOmTahevToSEhIwdOhQ2Nraonfv3hg/fjxOnTqFrKwsrFy5EgBQrVo13LhxQ2U7169fxwcffICBAwdi9erVOH36NAIDA2FoaKgSOFatWoXg4GAcOHAAiYmJGDhwIFq1aoWOHTu+tD86OjpYsGAB6tSpg4sXL2LEiBH44osvsGjRIgDPwkOHDh0waNAgzJ8/H3p6etizZ4/y6wFCQkKwbNkyzJs3D++++y5u3ryJ06dPv3S/z8vJycHMmTPx448/onr16qhRowYuXryIAQMG4Pvvv4cQAnPmzMEHH3yAc+fOwczMDAqFAp07d8aDBw+wdu1a1KtXDydPnoSuri5MTEzQp08frFy5Eh9//LFyPwU/m5mZaVSfJjQOI3PnzkVgYCACAgIAAEuWLMG2bduwYsUKfPnll4XaJyQkoFWrVujXrx+AZwOc+vbtiwMHDpSxdCIiKi9Vq1ZF586dsX79emUY2bx5MywtLdG+fXvo6OigWbNmyvZTp07FL7/8gt9++w1BQUEv3f769euhUCiwfPlyGBoaokmTJrh27RqGDx+ubKOvr49vvvlG+XOdOnWQmJiIjRs3onfv3jA1NYWRkRFyc3OLvSyzaNEi2NvbY+HChZDJZHBycsKNGzcwceJEhIaGKi9lNG3aFGFhYQAAR0dHLFy4EHFxcSUKI2PHjlX+v4ODA7799lt89tlnyjAya9YsuLm5KX8GgCZNmgAAHjx4gPnz52PhwoUYMGAAAKBevXp49913X7rf5z158gSLFi1SOS7vvfeeSpulS5fCwsIC//vf/9C1a1fs3r0bSUlJOHXqFBo0aAAAqFu3rrL9kCFD4OXlhZs3b8LW1ha3bt3C9u3bX3oWrKw0ukyTl5eH5ORkeHt7/7cBHR14e3sjMTFR7TpeXl5ITk5WXsq5ePEitm/fjg8++KDI/eTm5iIrK0tlIiKiV6t///74+eefkZubCwBYt24d+vTpAx0dHTx8+BDjx49Ho0aNYGFhAVNTU5w6dQpXrlwp0bZPnTqFpk2bqjyh09PTs1C7qKgouLq6wsrKCqampli6dGmJ9/H8vjw9PVUew9+qVSs8fPgQ165dU85r2rSpynoFH74lsXv3bnTo0AF2dnYwMzPDp59+ijt37ii/j6jgzEhR9eXm5ha5vKQMDAwK9SE9PR2BgYFwdHSEubk5qlSpgocPHypfw5SUFLz11lvKIPIid3d3NGnSBKtWrQIArF27FrVr10abNm3KVOvLaBRGMjIykJ+fD2tra5X51tbWSEtLU7tOv379MGXKFLz77rvQ19dHvXr10K5dO0yaNKnI/URERMDc3Fw52dvba1ImERGVQrdu3SCEwLZt23D16lXs3bsX/fv3BwCMHz8ev/zyC6ZPn469e/ciJSUFzs7OyMvLK7f9b9iwAePHj8fgwYOxc+dOpKSkICAgoFz38Tx9fX2Vn2UyWaExM+qkpqaia9euaNq0KX7++WckJycjKioKAJS1GhkZFbl+ccuA/55oKoRQznvy5Ina7bz4vUcDBgxASkoK5s+fj4SEBKSkpKB69eolqqvAkCFDEB0dDeDZJZqAgIBX/v1Kr3zYbXx8PKZPn45Fixbh8OHD2LJlC7Zt24apU6cWuU5ISAgyMzOV09WrV191mUREbzxDQ0P06NED69atw08//YSGDRuiRYsWAJ4Nxhw4cCA++ugjODs7w8bGRjmYsiQaNWqEo0ePqty8sH//fpU2+/btg5eXF0aMGIHmzZujfv36uHDhgkobAwMD5biL4vaVmJio8mG+b98+mJmZ4a233ipxzUVJTk6GQqHAnDlz0LJlSzRo0KDQuJWmTZsiLi5O7fqOjo4wMjIqcrmVlRWAZ7dGFyjpM1T27duH0aNH44MPPkCTJk0gl8uRkZGhUte1a9dw9uzZIrfxySef4PLly1iwYAFOnjypvJT0KmkURiwtLaGrq4v09HSV+enp6UVev5s8eTI+/fRTDBkyBM7Ozvjoo48wffp0REREFJlA5XI5qlSpojIREdGr179/f+U4wIKzIsCzD9AtW7YgJSUF//77L/r161eiswgF+vXrB5lMhsDAQJw8eRLbt2/H7NmzVdo4Ojri0KFD2LFjB86ePYvJkyfj4MGDKm0cHBxw9OhRnDlzBhkZGWrPGIwYMQJXr17FqFGjcPr0aWzduhVhYWEIDg4ul1tf69evjydPnuD777/HxYsXsWbNGixZskSlTUhICA4ePIgRI0bg6NGjOH36NBYvXoyMjAwYGhpi4sSJ+OKLL7B69WpcuHAB+/fvx/Lly5Xbt7e3R3h4OM6dO4dt27Zhzpw5JarN0dERa9aswalTp3DgwAH0799f5WxI27Zt0aZNG/Ts2RO7du3CpUuX8OeffyI2NlbZpmrVqujRowcmTJiA999/v1wC3MtoNIDVwMAArq6uiIuLQ/fu3QE8G/0cFxdX5ACmnJycQgdfV1cXgOopKCKiyk4b7m567733UK1aNZw5c0Z54wHw7OaFQYMGwcvLC5aWlpg4caJG4/lMTU3x+++/47PPPkPz5s3RuHFjzJw5Ez179lS2GTZsGI4cOQI/Pz/IZDL07dsXI0aMwJ9//qlsExgYiPj4eLi5ueHhw4fYs2cPHBwcVPZlZ2eH7du3Y8KECWjWrBmqVauGwYMH4+uvvy79C/OcZs2aYe7cuZg5cyZCQkLQpk0bREREwN/fX9mmQYMG2LlzJyZNmgR3d3cYGRnBw8MDffv2BfDsD3U9PT2Ehobixo0bsLW1xWeffQbg2eWjn376CcOHD0fTpk3xzjvv4Ntvv0WvXr1eWtvy5csxdOhQtGjRAvb29pg+fTrGjx+v0ubnn3/G+PHj0bdvX2RnZ6N+/fqYMWOGSpvBgwdj/fr1GDRoUFlfrhKRCQ0TQUxMDAYMGIAffvgB7u7uiIyMxMaNG3H69GlYW1vD398fdnZ2iIiIAPDsvvC5c+di6dKl8PDwwPnz5zF8+HC4uroiJiamRPvMysqCubk5MjMzeZbkOZX5FlH2rXxow4dfZfP48WNcunQJderUKfXXqRNJbc2aNRg3bhxu3LgBAwODYtsW954v6ee3xrf2+vn54fbt2wgNDUVaWhpcXFwQGxurHNR65coVlTMhX3/9NWQyGb7++mtcv34dVlZW6Natm/LhLkRUeTBoEWm3nJwc3Lx5EzNmzMCwYcNeGkTKS6keBx8UFFTkZZn4+HjVHejpISwsTHkvNxER0ets3bp1GDZsmNpltWvXxokTJyq4oooza9YsTJs2DW3atEFISEiF7ZffTUNERPScDz/8EB4eHmqXvXg7cGUTHh6u0WPxywvDCBER0XPMzMxe6aPPqbBKH0Z4DZuIpMC7BelNUR7vde38rmEiotdUwWn8gseCE1V2Be/1slzCqvRnRoiIKpKuri4sLCyU33FibGz8yh+lTSQFIQRycnJw69YtWFhYKJ8hVhoMI0RE5azgidQl/dI1Im1mYWFR7LcolwTDCBFROZPJZLC1tUWNGjXUPq6cqLLQ19cv0xmRAgwjRESviK6ubrn8Q01U2XEAKxEREUmKYYSIiIgkxTBCREREkmIYISIiIkkxjBAREZGkGEaIiIhIUgwjREREJCmGESIiIpIUwwgRERFJimGEiIiIJMUwQkRERJJiGCEiIiJJMYwQERGRpBhGiIiISFIMI0RERCQphhEiIiKSFMMIERERSYphhIiIiCTFMEJERESSYhghIiIiSTGMEBERkaQYRoiIiEhSDCNEREQkKYYRIiIikhTDCBEREUmqVGEkKioKDg4OMDQ0hIeHB5KSkops265dO8hkskJTly5dSl00ERERVR4ah5GYmBgEBwcjLCwMhw8fRrNmzeDj44Nbt26pbb9lyxbcvHlTOR0/fhy6urro1atXmYsnIiIi7adxGJk7dy4CAwMREBCAxo0bY8mSJTA2NsaKFSvUtq9WrRpsbGyU065du2BsbFxsGMnNzUVWVpbKRERERJWTRmEkLy8PycnJ8Pb2/m8DOjrw9vZGYmJiibaxfPly9OnTByYmJkW2iYiIgLm5uXKyt7fXpEwiIiLSIhqFkYyMDOTn58Pa2lplvrW1NdLS0l66flJSEo4fP44hQ4YU2y4kJASZmZnK6erVq5qUSURERFpEryJ3tnz5cjg7O8Pd3b3YdnK5HHK5vIKqIiIiIilpdGbE0tISurq6SE9PV5mfnp4OGxubYtfNzs7Ghg0bMHjwYM2rJCIiokpLozBiYGAAV1dXxMXFKecpFArExcXB09Oz2HU3bdqE3NxcfPLJJ6WrlIiIiColjS/TBAcHY8CAAXBzc4O7uzsiIyORnZ2NgIAAAIC/vz/s7OwQERGhst7y5cvRvXt3VK9evXwqJyIiokpB4zDi5+eH27dvIzQ0FGlpaXBxcUFsbKxyUOuVK1ego6N6wuXMmTP4559/sHPnzvKpmoiIiCqNUg1gDQoKQlBQkNpl8fHxheY1bNgQQojS7IqIiIgqOX43DREREUmKYYSIiIgkxTBCREREkmIYISIiIkkxjBAREZGkGEaIiIhIUgwjREREJCmGESIiIpIUwwgRERFJimGEiIiIJMUwQkRERJJiGCEiIiJJMYwQERGRpBhGiIiISFIMI0RERCQphhEiIiKSFMMIERERSYphhIiIiCTFMEJERESSYhghIiIiSTGMEBERkaQYRoiIiEhSDCNEREQkKYYRIiIikhTDCBEREUmKYYSIiIgkxTBCREREkmIYISIiIkkxjBAREZGkGEaIiIhIUgwjREREJCk9qQsgItIGDl9uq9D9pc7oUqH7I5JSqc6MREVFwcHBAYaGhvDw8EBSUlKx7e/fv4+RI0fC1tYWcrkcDRo0wPbt20tVMBEREVUuGp8ZiYmJQXBwMJYsWQIPDw9ERkbCx8cHZ86cQY0aNQq1z8vLQ8eOHVGjRg1s3rwZdnZ2uHz5MiwsLMqjfiIiItJyGoeRuXPnIjAwEAEBAQCAJUuWYNu2bVixYgW+/PLLQu1XrFiBu3fvIiEhAfr6+gAABweHslVNRERElYZGl2ny8vKQnJwMb2/v/zagowNvb28kJiaqXee3336Dp6cnRo4cCWtra7z99tuYPn068vPzi9xPbm4usrKyVCYiIiKqnDQKIxkZGcjPz4e1tbXKfGtra6Slpald5+LFi9i8eTPy8/Oxfft2TJ48GXPmzMG3335b5H4iIiJgbm6unOzt7TUpk4iIiLTIK7+1V6FQoEaNGli6dClcXV3h5+eHr776CkuWLClynZCQEGRmZiqnq1evvuoyiYiISCIajRmxtLSErq4u0tPTVeanp6fDxsZG7Tq2trbQ19eHrq6ucl6jRo2QlpaGvLw8GBgYFFpHLpdDLpdrUhoRERFpKY3OjBgYGMDV1RVxcXHKeQqFAnFxcfD09FS7TqtWrXD+/HkoFArlvLNnz8LW1lZtECEiIqI3i8aXaYKDg7Fs2TKsWrUKp06dwvDhw5Gdna28u8bf3x8hISHK9sOHD8fdu3cxZswYnD17Ftu2bcP06dMxcuTI8usFERERaS2Nb+318/PD7du3ERoairS0NLi4uCA2NlY5qPXKlSvQ0fkv49jb22PHjh0YN24cmjZtCjs7O4wZMwYTJ04sv14QERGR1irV4+CDgoIQFBSkdll8fHyheZ6enti/f39pdkVERESVHL8oj4iIiCTFMEJERESSYhghIiIiSTGMEBERkaQYRoiIiEhSDCNEREQkKYYRIiIikhTDCBEREUmKYYSIiIgkxTBCREREkmIYISIiIkkxjBAREZGkGEaIiIhIUgwjREREJCmGESIiIpIUwwgRERFJimGEiIiIJMUwQkRERJJiGCEiIiJJMYwQERGRpBhGiIiISFIMI0RERCQphhEiIiKSFMMIERERSYphhIiIiCTFMEJERESSYhghIiIiSTGMEBERkaQYRoiIiEhSDCNEREQkKYYRIiIikhTDCBEREUmKYYSIiIgkVaowEhUVBQcHBxgaGsLDwwNJSUlFto2OjoZMJlOZDA0NS10wERERVS4ah5GYmBgEBwcjLCwMhw8fRrNmzeDj44Nbt24VuU6VKlVw8+ZN5XT58uUyFU1ERESVh8ZhZO7cuQgMDERAQAAaN26MJUuWwNjYGCtWrChyHZlMBhsbG+VkbW1dpqKJiIio8tAojOTl5SE5ORne3t7/bUBHB97e3khMTCxyvYcPH6J27dqwt7eHr68vTpw4Uex+cnNzkZWVpTIRERFR5aRRGMnIyEB+fn6hMxvW1tZIS0tTu07Dhg2xYsUKbN26FWvXroVCoYCXlxeuXbtW5H4iIiJgbm6unOzt7TUpk4iIiLTIK7+bxtPTE/7+/nBxcUHbtm2xZcsWWFlZ4YcffihynZCQEGRmZiqnq1evvuoyiYiISCJ6mjS2tLSErq4u0tPTVeanp6fDxsamRNvQ19dH8+bNcf78+SLbyOVyyOVyTUojIiIiLaXRmREDAwO4uroiLi5OOU+hUCAuLg6enp4l2kZ+fj6OHTsGW1tbzSolIiKiSkmjMyMAEBwcjAEDBsDNzQ3u7u6IjIxEdnY2AgICAAD+/v6ws7NDREQEAGDKlClo2bIl6tevj/v37+O7777D5cuXMWTIkPLtCREREWkljcOIn58fbt++jdDQUKSlpcHFxQWxsbHKQa1XrlyBjs5/J1zu3buHwMBApKWloWrVqnB1dUVCQgIaN25cfr0gIiIiraVxGAGAoKAgBAUFqV0WHx+v8vO8efMwb9680uyGiIiI3gD8bhoiIiKSFMMIERERSYphhIiIiCTFMEJERESSYhghIiIiSZXqbhoiIqo8HL7cVqH7S53RpcL2xb6Vn1fZN54ZISIiIkkxjBAREZGkGEaIiIhIUgwjREREJCmGESIiIpIUwwgRERFJimGEiIiIJMUwQkRERJJiGCEiIiJJMYwQERGRpBhGiIiISFIMI0RERCQphhEiIiKSFMMIERERSYphhIiIiCTFMEJERESSYhghIiIiSTGMEBERkaQYRoiIiEhSDCNEREQkKYYRIiIikhTDCBEREUmKYYSIiIgkxTBCREREkmIYISIiIkkxjBAREZGkGEaIiIhIUqUKI1FRUXBwcIChoSE8PDyQlJRUovU2bNgAmUyG7t27l2a3REREVAlpHEZiYmIQHByMsLAwHD58GM2aNYOPjw9u3bpV7HqpqakYP348WrduXepiiYiIqPLROIzMnTsXgYGBCAgIQOPGjbFkyRIYGxtjxYoVRa6Tn5+P/v3745tvvkHdunXLVDARERFVLhqFkby8PCQnJ8Pb2/u/DejowNvbG4mJiUWuN2XKFNSoUQODBw8u0X5yc3ORlZWlMhEREVHlpFEYycjIQH5+PqytrVXmW1tbIy0tTe06//zzD5YvX45ly5aVeD8REREwNzdXTvb29pqUSURERFrkld5N8+DBA3z66adYtmwZLC0tS7xeSEgIMjMzldPVq1dfYZVEREQkJT1NGltaWkJXVxfp6ekq89PT02FjY1Oo/YULF5Camopu3bop5ykUimc71tPDmTNnUK9evULryeVyyOVyTUojIiIiLaXRmREDAwO4uroiLi5OOU+hUCAuLg6enp6F2js5OeHYsWNISUlRTh9++CHat2+PlJQUXn4hIiIizc6MAEBwcDAGDBgANzc3uLu7IzIyEtnZ2QgICAAA+Pv7w87ODhERETA0NMTbb7+tsr6FhQUAFJpPREREbyaNw4ifnx9u376N0NBQpKWlwcXFBbGxscpBrVeuXIGODh/sSkRERCWjcRgBgKCgIAQFBaldFh8fX+y60dHRpdklERERVVI8hUFERESSYhghIiIiSTGMEBERkaQYRoiIiEhSDCNEREQkKYYRIiIikhTDCBEREUmKYYSIiIgkxTBCREREkmIYISIiIkkxjBAREZGkGEaIiIhIUgwjREREJCmGESIiIpIUwwgRERFJimGEiIiIJMUwQkRERJJiGCEiIiJJMYwQERGRpBhGiIiISFIMI0RERCQphhEiIiKSFMMIERERSYphhIiIiCTFMEJERESSYhghIiIiSTGMEBERkaQYRoiIiEhSDCNEREQkKYYRIiIikhTDCBEREUmKYYSIiIgkVaowEhUVBQcHBxgaGsLDwwNJSUlFtt2yZQvc3NxgYWEBExMTuLi4YM2aNaUumIiIiCoXjcNITEwMgoODERYWhsOHD6NZs2bw8fHBrVu31LavVq0avvrqKyQmJuLo0aMICAhAQEAAduzYUebiiYiISPtpHEbmzp2LwMBABAQEoHHjxliyZAmMjY2xYsUKte3btWuHjz76CI0aNUK9evUwZswYNG3aFP/880+ZiyciIiLtp1EYycvLQ3JyMry9vf/bgI4OvL29kZiY+NL1hRCIi4vDmTNn0KZNmyLb5ebmIisrS2UiIiKiykmjMJKRkYH8/HxYW1urzLe2tkZaWlqR62VmZsLU1BQGBgbo0qULvv/+e3Ts2LHI9hERETA3N1dO9vb2mpRJREREWqRC7qYxMzNDSkoKDh48iGnTpiE4OBjx8fFFtg8JCUFmZqZyunr1akWUSURERBLQ06SxpaUldHV1kZ6erjI/PT0dNjY2Ra6no6OD+vXrAwBcXFxw6tQpREREoF27dmrby+VyyOVyTUojIiIiLaXRmREDAwO4uroiLi5OOU+hUCAuLg6enp4l3o5CoUBubq4muyYiIqJKSqMzIwAQHByMAQMGwM3NDe7u7oiMjER2djYCAgIAAP7+/rCzs0NERASAZ+M/3NzcUK9ePeTm5mL79u1Ys2YNFi9eXL49ISIiIq2kcRjx8/PD7du3ERoairS0NLi4uCA2NlY5qPXKlSvQ0fnvhEt2djZGjBiBa9euwcjICE5OTli7di38/PzKrxdERESktTQOIwAQFBSEoKAgtcteHJj67bff4ttvvy3NboiIiOgNwO+mISIiIkkxjBAREZGkGEaIiIhIUgwjREREJCmGESIiIpIUwwgRERFJimGEiIiIJMUwQkRERJJiGCEiIiJJMYwQERGRpBhGiIiISFIMI0RERCQphhEiIiKSFMMIERERSYphhIiIiCTFMEJERESSYhghIiIiSTGMEBERkaQYRoiIiEhSDCNEREQkKYYRIiIikhTDCBEREUmKYYSIiIgkxTBCREREkmIYISIiIkkxjBAREZGkGEaIiIhIUgwjREREJCmGESIiIpIUwwgRERFJimGEiIiIJMUwQkRERJJiGCEiIiJJlSqMREVFwcHBAYaGhvDw8EBSUlKRbZctW4bWrVujatWqqFq1Kry9vYttT0RERG8WjcNITEwMgoODERYWhsOHD6NZs2bw8fHBrVu31LaPj49H3759sWfPHiQmJsLe3h7vv/8+rl+/XubiiYiISPtpHEbmzp2LwMBABAQEoHHjxliyZAmMjY2xYsUKte3XrVuHESNGwMXFBU5OTvjxxx+hUCgQFxdX5uKJiIhI+2kURvLy8pCcnAxvb+//NqCjA29vbyQmJpZoGzk5OXjy5AmqVatWZJvc3FxkZWWpTERERFQ5aRRGMjIykJ+fD2tra5X51tbWSEtLK9E2Jk6ciJo1a6oEmhdFRETA3NxcOdnb22tSJhEREWmRCr2bZsaMGdiwYQN++eUXGBoaFtkuJCQEmZmZyunq1asVWCURERFVJD1NGltaWkJXVxfp6ekq89PT02FjY1PsurNnz8aMGTOwe/duNG3atNi2crkccrlck9KIiIhIS2l0ZsTAwACurq4qg08LBqN6enoWud6sWbMwdepUxMbGws3NrfTVEhERUaWj0ZkRAAgODsaAAQPg5uYGd3d3REZGIjs7GwEBAQAAf39/2NnZISIiAgAwc+ZMhIaGYv369XBwcFCOLTE1NYWpqWk5doWIiIi0kcZhxM/PD7dv30ZoaCjS0tLg4uKC2NhY5aDWK1euQEfnvxMuixcvRl5eHj7++GOV7YSFhSE8PLxs1RMREZHW0ziMAEBQUBCCgoLULouPj1f5OTU1tTS7ICIiojcEv5uGiIiIJMUwQkRERJJiGCEiIiJJMYwQERGRpBhGiIiISFIMI0RERCQphhEiIiKSFMMIERERSYphhIiIiCTFMEJERESSYhghIiIiSTGMEBERkaQYRoiIiEhSDCNEREQkKYYRIiIikhTDCBEREUmKYYSIiIgkxTBCREREkmIYISIiIkkxjBAREZGkGEaIiIhIUgwjREREJCmGESIiIpIUwwgRERFJimGEiIiIJMUwQkRERJJiGCEiIiJJMYwQERGRpBhGiIiISFIMI0RERCQphhEiIiKSFMMIERERSYphhIiIiCRVqjASFRUFBwcHGBoawsPDA0lJSUW2PXHiBHr27AkHBwfIZDJERkaWtlYiIiKqhDQOIzExMQgODkZYWBgOHz6MZs2awcfHB7du3VLbPicnB3Xr1sWMGTNgY2NT5oKJiIioctE4jMydOxeBgYEICAhA48aNsWTJEhgbG2PFihVq27/zzjv47rvv0KdPH8jl8jIXTERERJWLRmEkLy8PycnJ8Pb2/m8DOjrw9vZGYmJiuRWVm5uLrKwslYmIiIgqJ43CSEZGBvLz82Ftba0y39raGmlpaeVWVEREBMzNzZWTvb19uW2biIiIXi+v5d00ISEhyMzMVE5Xr16VuiQiIiJ6RfQ0aWxpaQldXV2kp6erzE9PTy/XwalyuZzjS4iIiN4QGp0ZMTAwgKurK+Li4pTzFAoF4uLi4OnpWe7FERERUeWn0ZkRAAgODsaAAQPg5uYGd3d3REZGIjs7GwEBAQAAf39/2NnZISIiAsCzQa8nT55U/v/169eRkpICU1NT1K9fvxy7QkRERNpI4zDi5+eH27dvIzQ0FGlpaXBxcUFsbKxyUOuVK1ego/PfCZcbN26gefPmyp9nz56N2bNno23btoiPjy97D4iIiEiraRxGACAoKAhBQUFql70YMBwcHCCEKM1uiIiI6A3wWt5NQ0RERG8OhhEiIiKSFMMIERERSYphhIiIiCTFMEJERESSYhghIiIiSTGMEBERkaQYRoiIiEhSDCNEREQkKYYRIiIikhTDCBEREUmKYYSIiIgkxTBCREREkmIYISIiIkkxjBAREZGkGEaIiIhIUgwjREREJCmGESIiIpIUwwgRERFJimGEiIiIJMUwQkRERJJiGCEiIiJJMYwQERGRpBhGiIiISFIMI0RERCQphhEiIiKSFMMIERERSYphhIiIiCTFMEJERESSYhghIiIiSTGMEBERkaQYRoiIiEhSpQojUVFRcHBwgKGhITw8PJCUlFRs+02bNsHJyQmGhoZwdnbG9u3bS1UsERERVT4ah5GYmBgEBwcjLCwMhw8fRrNmzeDj44Nbt26pbZ+QkIC+ffti8ODBOHLkCLp3747u3bvj+PHjZS6eiIiItJ/GYWTu3LkIDAxEQEAAGjdujCVLlsDY2BgrVqxQ237+/Pno1KkTJkyYgEaNGmHq1Klo0aIFFi5cWObiiYiISPvpadI4Ly8PycnJCAkJUc7T0dGBt7c3EhMT1a6TmJiI4OBglXk+Pj749ddfi9xPbm4ucnNzlT9nZmYCALKysjQpFwCgyM3ReJ3SKk19ZcG+lQ/2rfywb+WnIvvHvpUf9k39OkKI4hsKDVy/fl0AEAkJCSrzJ0yYINzd3dWuo6+vL9avX68yLyoqStSoUaPI/YSFhQkAnDhx4sSJE6dKMF29erXYfKHRmZGKEhISonI2RaFQ4O7du6hevTpkMtkr3XdWVhbs7e1x9epVVKlS5ZXuq6Kxb9qrMvePfdNO7Jt2qui+CSHw4MED1KxZs9h2GoURS0tL6OrqIj09XWV+eno6bGxs1K5jY2OjUXsAkMvlkMvlKvMsLCw0KbXMqlSpUunehAXYN+1VmfvHvmkn9k07VWTfzM3NX9pGowGsBgYGcHV1RVxcnHKeQqFAXFwcPD091a7j6emp0h4Adu3aVWR7IiIierNofJkmODgYAwYMgJubG9zd3REZGYns7GwEBAQAAPz9/WFnZ4eIiAgAwJgxY9C2bVvMmTMHXbp0wYYNG3Do0CEsXbq0fHtCREREWknjMOLn54fbt28jNDQUaWlpcHFxQWxsLKytrQEAV65cgY7OfydcvLy8sH79enz99deYNGkSHB0d8euvv+Ltt98uv16UI7lcjrCwsEKXiSoD9k17Veb+sW/aiX3TTq9r32RCvOx+GyIiIqJXh99NQ0RERJJiGCEiIiJJMYwQERGRpBhGiIiISFIMI0RERCQphhEiIiKSFMPIGyo9PR1TpkyRuoxXIjs7G3///bfUZRARUQkxjBTjwoULeO+996Qu45VIS0vDN998I3UZr8T58+fRvn17qct4Jf7991/o6upKXUa5yc7OxsqVK/HVV19h4cKFuHPnjtQlURFGjRqFvXv3Sl0GVVIMI8V4+PAh/ve//0ldRqkcPXq02OnMmTNSl0ilpM3PKWzcuDHu3r0LALh69SrefvttjBs3Drt27UJYWBgaN26MS5cuSVxl6Rw+fFil9jVr1qBVq1awt7fHu+++iw0bNkhYXdlFRUWhXbt2aNCgAWbOnIm0tDSpSypXCxcuhL+/v/I4rVmzBo0bN4aTkxMmTZqEp0+fSlxh6d28eROhoaF477330KhRIzRp0gTdunXD8uXLkZ+fL3V5AErxOPjKZMGCBcUuv379egVVUv5cXFwgk8nUfnAVzJfJZBJUVnbVqlUrdvnr8stVGj169Ch2eWZmptYeNwA4ffq08h/1kJAQ1KxZEykpKTA3N8fDhw/x0Ucf4auvvsL69eslrlRzAQEBmDNnDurUqYMff/wRo0ePRmBgID799FOcOXMGgYGByMnJwaBBg6QutdR27tyJ33//HbNnz8bkyZPRuXNnBAYG4oMPPlD5GhBt8+2332LWrFl4//33MW7cOFy+fBnfffcdxo0bBx0dHcybNw/6+vpaeTb50KFD8Pb2Rv369WFkZIRz586hX79+yMvLw/jx47FixQrExsbCzMxM0jrf6MfB6+jowNbWFgYGBmqX5+XlIS0tTSs/3CwtLTFr1ix06NBB7fITJ06gW7duWtk3ExMTDB8+HM7OzmqXX758Gd98841W9k1fXx8dO3ZUftfTi+7evYs//vhDK/sGPPudS0tLQ40aNVCvXj0sWbIEHTt2VC5PSEhAnz59cOXKFQmrLB1jY2OcOnUKtWvXRosWLTB8+HAEBgYql69fvx7Tpk3DiRMnJKyy9J4/dk+ePMEvv/yCFStWYPfu3bC2tsbAgQMREBCA+vXrS12qxurXr49Zs2ahR48e+Pfff+Hq6opVq1ahf//+AIBffvkFX3zxBc6dOydxpZp799130bFjR4SFhQEA1q5di4ULF2L//v24d+8e3nvvPbRp0wbz58+XtlDxBnNwcBAxMTFFLj9y5IjQ0dGpwIrKz/vvvy+mTp1a5PKUlBQhk8kqsKLy4+XlJSIjI4tcnpKSorXHzdnZWfz4449FLtfm96QQQshkMnHr1i0hhBA1a9YUx44dU1mempoqDA0NpSitzKpXry4OHTokhBCiRo0aIiUlRWX5+fPnhZGRkRSllQuZTCbS09MLzb98+bIICwsTtWvX1tr3ppGRkbh8+bLyZ319fXH8+HHlz6mpqcLY2FiK0srMyMhIXLhwQflzfn6+0NfXF2lpaUIIIXbu3Clq1qwpVXlK2nterRy4uroiOTm5yOVFXebQBp999hkcHByKXF6rVi2sXLmy4goqR126dMH9+/eLXF6tWjX4+/tXXEHlyNXVFYcPHy5yuVwuR61atSqwovLXoUMHtGjRAllZWYXGLl2+fBnVq1eXqLKy6dy5MxYvXgwAaNu2LTZv3qyyfOPGjVp51uBlatWqhfDwcFy6dAmxsbFSl1MqNjY2OHnyJADg3LlzyM/PV/4MPDuTXKNGDanKK5MaNWrg5s2byp/T09Px9OlTVKlSBQDg6OioHMclpTf6Ms3JkyeRk5MDNzc3tcufPHmCGzduoHbt2hVcGb2pcnNzkZ+fD2NjY6lLeSVevObesmVL+Pj4KH+eMGECrl27hp9++qmiSyuzGzduoFWrVqhVqxbc3NywePFiuLq6olGjRjhz5gz279+PX375BR988IHUpZZKnTp1cOjQIa0Ni8WZPHkyfvjhB/j6+iIuLg5+fn5Yv349QkJCIJPJMG3aNHz88ceYO3eu1KVqbOzYsYiLi8N3330HuVyOqVOnQgiBPXv2AAB27NiBkSNH4vz585LW+UaHESKi8nT//n3MmDEDv//+Oy5evAiFQgFbW1u0atUK48aNK/IPH5KWQqHAjBkzkJiYCC8vL3z55ZeIiYnBF198gZycHHTr1g0LFy6EiYmJ1KVq7OHDhxg8eDC2bNmC/Px8eHp6Ys2aNahbty6AZ4OSMzMz0atXL0nrZBipxE6ePImFCxciMTFReRuejY0NPD09ERQUhMaNG0tcYenl5eXh119/LdQ3Ly8v+Pr6FjkoWVukpaXhwIEDKn3z8PCAjY2NxJWVr9zcXADPLj+RduGx0y6PHz/G06dPYWpqKnUpajGMFGPSpElIS0vDihUrpC5FY3/++Se6d++OFi1awMfHR3l3Rnp6Onbt2oXk5GRs3bpV5RS5tjh//jx8fHxw48YNeHh4qPTtwIEDeOutt/Dnn39q5fX57OxsDBs2DBs2bIBMJlPexnz37l0IIdC3b1/88MMPWn0ZZ9euXZg3bx4SExORlZUFAKhSpQo8PT0RHBwMb29viSssH5Xxw5rHTvu9tn2TaOCsVvj0009F+/btpS6jVJo2bSomT55c5PKwsDDh7OxcgRWVH29vb+Hr6ysyMzMLLcvMzBS+vr7i/fffl6Cyshs8eLBwdHQUsbGx4unTp8r5T58+FTt27BANGjQQQ4YMkbDCsomOjhZ6enqiT58+YuXKlWL79u1i+/btYuXKlaJv375CX19frF69WuoyS23nzp2ic+fOwsLCQujo6AgdHR1hYWEhOnfuLHbt2iV1eWXCY6e9tKFvDCOVlKGhoTh9+nSRy0+fPq21t1AaGRkVuiX0eUePHtXaWygtLCzEvn37ilz+zz//CAsLiwqsqHw5OjqKhQsXFrk8KipK1K9fvwIrKj+V/cOax047j5229O2NDyO3b98WM2fOFN27dxctW7YULVu2FN27dxezZs1SPg9BGzk5OYk5c+YUuXzOnDmiYcOGFVhR+bG1tRW///57kct/++03YWtrW4EVlZ8qVaqIgwcPFrk8KSlJVKlSpQIrKl9yubzShuTK/GEtBI+dth47benbG/2ckYMHD6JBgwZYsGABzM3N0aZNG7Rp0wbm5uZYsGABnJyccOjQIanLLJUpU6Zg4sSJ+PDDD7FgwQLExMQgJiYGCxYsgK+vL0JCQjBt2jSpyyyVIUOGwN/fH/PmzcPRo0eRnp6O9PR0HD16FPPmzcPAgQMxdOhQqcssla5du2Lo0KE4cuRIoWVHjhzB8OHD0a1bNwkqKx9NmjTB8uXLi1y+YsUKrR1YfeXKlWLHTHTo0AHXrl2rwIrKF4+ddh47benbGz2AtWXLlmjWrBmWLFlS6Ps+hBD47LPPcPToUSQmJkpUYdkkJCRgwYIFau+mGTNmDDw9PSWusPRmzpyJ+fPnIy0tTXnshBCwsbHB2LFj8cUXX0hcYencu3cP/fr1w44dO1C1alXlg5Zu3bqF+/fvw8fHB+vXr4eFhYW0hZZSfHw8unbtirp168Lb21tl8HFcXBwuXryIbdu2oU2bNhJXqjlXV1d06NABs2bNUrt84sSJ2L17d7EPWnyd8dhp57HTlr690WHEyMgIR44cgZOTk9rlp0+fRvPmzfHo0aMKroxK6uLFi0hPTwfwLGjVqVNH4orKx6lTp7B///5CIbKo96o2SU1NxeLFi9X272VPDn6dVeYP6wI8dtp37LSlb290GKlTpw6++eabIh8dvnr1aoSGhiI1NbViCyMirVRZP6zfBJX52GlD397oMBIVFYXPP/8cw4YNQ4cOHQolxmXLlmH27NkYMWKExJWWP21+hgrAB7pVJiNGjMCUKVNgaWkpdSmkIR47Ki9v9ADWkSNHYtWqVThw4AB69uwJT09PeHp6omfPnjhw4ACio6MrZRABgGvXrmntGZ8///wTzZs3x5EjR+Dr64vQ0FCEhobC19cX//77L1q0aIEdO3ZIXWapnD9/Ho0aNcKAAQNw5MgRKBQKKBQKHDlyBP7+/mjSpInk3yFR3tauXat8gFZlM2LECGRkZEhdxivDY6edXse+vdFnRp735MkT5cGxtLSEvr6+xBVRUZo1awZfX19MmTJF7fLw8HBs2bIFR48ereDKyq5jx44wMTHB6tWrld+qWSArKwv+/v549OiR1oYtdczMzPDvv/8qvyujMqlSpQpSUlIqZd8AHjtt9Tr2TU/qAl4X+vr6sLW1lbqMcpWRkYEVK1aoPd0/cOBAWFlZSVxh6Zw9exb9+/cvcnnfvn0xc+bMCqyo/Ozbtw9JSUmFggjw7B+QqVOnwsPDQ4LKqDT4t572qszH7nXs2xt9maYyq8zPUHFwcMC2bduKXL5t2zbUrl27AisqPxYWFsVePktNTdXa23qL8uDBg9fqLzQqOR47Ki88M1JJjRo1Cr169Sr2GSqjRo3SymeoTJkyBf369UN8fLzaW9ViY2Oxfv16iassnYIHuk2ePFntoOpvv/0Wo0aNkrjK8nHhwgWsXLkSFy9eRGRkJGrUqIE///wTtWrVQpMmTaQur1w8ePBA6hJeCR477fZa9q3iH/pKFcHQ0FCcOnWqyOWnTp3S2kc3CyHEvn37hJ+fn6hVq5YwMDAQBgYGolatWsLPz08kJCRIXV6ZzJgxQ9ja2gqZTKb8UiuZTCZsbW3FzJkzpS6vXMTHxwsjIyPh7e0tDAwMxIULF4QQQkRERIiePXtKXF3ZnT9/Xnz11Veib9++Ij09XQghxPbt28Xx48clrqzseOy01+vcN4aRSsrBwUGsWrWqyOWrVq0StWvXrriCSGMXLlwQCQkJIiEhQVy8eFHqcspVy5Ytld+dZGpqqvxAO3DggLCzs5OytDKr7B/WPHba6XXvG8NIJbVw4UIhl8vF6NGjxdatW8X+/fvF/v37xdatW8Xo0aOFkZGRiIqKkrpMekOZmJgoA9bzH2iXLl0ScrlcytLKrDJ/WAvBY6etXve+ccxIJTVy5EhYWlpi3rx5WLRoEfLz8wEAurq6cHV1RXR0NHr37i1xla8GH+j2+rOwsMDNmzcLPb7/yJEjsLOzk6iq8nHs2DG1Y5Zq1Kjx2j3boTR47LTT6943hpFKzM/PD35+fm/cM1SuXbv2WnwLZWn8+eef6N69O1q0aAFfX1+VAay7du1CixYtsHXrVvj4+Ehcadn06dMHEydOxKZNmyCTyaBQKLBv3z6MHz++yK9n0BaV+cMa4LHTVq9936Q+NUNE/2natKmYPHlykcvDwsKEs7NzBVb0auTm5oohQ4YIPT09IZPJhL6+vtDR0RGffPKJePr0qdTllcnnn38u3n33XXHz5k1hZmYmzp07J/755x9Rt25dER4eLnV5ZcZjp51e977xCayklSrrA92MjIyQkpKChg0bql1+5swZuLi4VJpvkr569SqOHTuGhw8fonnz5nB0dJS6pDLLy8vDyJEjER0djfz8fOjp6SE/Px/9+vVDdHQ0dHV1pS6xXPDYaZfXvW8MI6R1Dh48CB8fHxgbG6t9zkhOTg527NgBNzc3iSvVXKNGjRAYGIjg4GC1y+fOnYulS5fi9OnTFVxZxbh69SrCwsK0drzP8yrjh3VxeOy0w+vaN4YR0jotW7ZEs2bNin2g29GjR7XygW6bNm1Cv3790Llz52If6NazZ0+JK301Cr7osGDAdWVSmT6s1eGx006vS98YRkjrGBkZ4ciRI3ByclK7/PTp02jevLnWXspISEjAggUL1N5NM2bMGHh6ekpcYen99ttvxS6/ePEiPv/880r5gabtH9Y8dtp77IrzuvSNd9OQ1rGxsUFSUlKRYSQpKUl5RkEbeXl5wcvLS+oyXonu3btDJpMV+0VdL57t0hYl+bDWZjx22klb+sYzI6R1oqKi8Pnnn2PYsGFqv79l2bJlmD17NkaMGCFxpfQiOzs7LFq0CL6+vmqXp6SkwNXVVfK/0kpDR0enRB/W2tg3gMdOW4+dtvSN39pLWmfkyJFYtWoVDhw4gJ49e8LT0xOenp7o2bMnDhw4gOjo6EobRCZNmoRBgwZJXUapubq6Ijk5ucjlL/tH83Vma2uLLVu2QKFQqJ0OHz4sdYllwmOnnbSlbwwjpJX8/Pywf/9+5OTk4Pr167h+/TpycnKwf//+SvtkWeDZA91SU1OlLqPUJkyYUOwlqPr162PPnj0VWFH5qcwf1gCPnbYeO23pGy/TEBGVg7179yI7OxudOnVSuzw7OxuHDh1C27ZtK7gyepnKfOy0pW8MI0Svmcr6QDcioqIwjBC9RirzA92IiIrCMEL0GqnMD3QjIioKwwjRa6SyP9CNiEgd3k1D9BopeKBbUbT9gW5EROrwCaxEr5Hx48dj6NChSE5OLvaBbkRElQkv0xC9ZmJiYjBv3jwkJycrn4qoq6sLV1dXBAcHV+rnqBDRm4lhhOg19eTJE2RkZAAALC0toa+vL3FFRESvBsMIERERSYoDWImIiEhSDCNEREQkKYYRIiIikhTDCBEREUmKYYSokmnXrh3Gjh0rdRkIDw+Hi4uL1GUQkRZgGCGiV2L8+PGIi4uTuowSGThwILp37y51GURvLIYRItJIXl5eidqZmpqievXqr7ia4j158kTS/RNRyTCMEFViubm5GD9+POzs7GBiYgIPDw/Ex8crl9+5cwd9+/aFnZ0djI2N4ezsjJ9++kllG+3atUNQUBDGjh0LS0tL+Pj4ID4+HjKZDHFxcXBzc4OxsTG8vLxw5swZ5XovXqYpOPswe/Zs2Nraonr16hg5cqRKYLh58ya6dOkCIyMj1KlTB+vXr4eDgwMiIyNL1F+ZTIbFixfjww8/hImJCaZNm4b8/HwMHjwYderUgZGRERo2bIj58+er1Llq1Sps3boVMpkMMplM+RpdvXoVvXv3hoWFBapVqwZfX1+kpqaW+PUnopJhGCGqxIKCgpCYmIgNGzbg6NGj6NWrFzp16oRz584BAB4/fgxXV1ds27YNx48fx9ChQ/Hpp58W+rK+VatWwcDAAPv27cOSJUuU87/66ivMmTMHhw4dgp6eHgYNGlRsPXv27MGFCxewZ88erFq1CtHR0YiOjlYu9/f3x40bNxAfH4+ff/4ZS5cuxa1btzTqc3h4OD766CMcO3YMgwYNgkKhwFtvvYVNmzbh5MmTCA0NxaRJk7Bx40YAzy4n9e7dG506dcLNmzdx8+ZNeHl54cmTJ/Dx8YGZmRn27t2Lffv2wdTUFJ06dSrx2SEiKiFBRJVK27ZtxZgxY8Tly5eFrq6uuH79usryDh06iJCQkCLX79Kli/j8889Vtte8eXOVNnv27BEAxO7du5Xztm3bJgCIR48eCSGECAsLE82aNVMuHzBggKhdu7Z4+vSpcl6vXr2En5+fEEKIU6dOCQDi4MGDyuXnzp0TAMS8efNK1HcAYuzYsS9tN3LkSNGzZ0+V2nx9fVXarFmzRjRs2FAoFArlvNzcXGFkZCR27NhRonqIqGT4rb1EldSxY8eQn5+PBg0aqMzPzc1VjuXIz8/H9OnTsXHjRly/fh15eXnIzc2FsbGxyjqurq5q99G0aVPl/9va2gIAbt26hVq1aqlt36RJE+jq6qqsc+zYMQDAmTNnoKenhxYtWiiX169fH1WrVi1plwEAbm5uheZFRUVhxYoVuHLlCh49eoS8vLyX3unz77//4vz58zAzM1OZ//jxY1y4cEGjmoioeAwjRJXUw4cPoauri+TkZJUAADwbXAoA3333HebPn4/IyEg4OzvDxMQEY8eOLXQZwsTERO0+nv/yPplMBgBQKBRF1vTil/3JZLJi25fGi7Vu2LAB48ePx5w5c+Dp6QkzMzN89913OHDgQLHbefjwIVxdXbFu3bpCy6ysrMq1ZqI3HcMIUSXVvHlz5Ofn49atW2jdurXaNvv27YOvry8++eQTAM+CxNmzZ9G4ceOKLBUA0LBhQzx9+hRHjhxRnok5f/487t27V6bt7tu3D15eXhgxYoRy3otnNgwMDJCfn68yr0WLFoiJiUGNGjVQpUqVMtVARMXjAFaiSqpBgwbo378//P39sWXLFly6dAlJSUmIiIjAtm3bAACOjo7YtWsXEhIScOrUKQwbNgzp6emS1Ovk5ARvb28MHToUSUlJOHLkCIYOHQojIyPlWZfScHR0xKFDh7Bjxw6cPXsWkydPxsGDB1XaODg44OjRozhz5gwyMjLw5MkT9O/fH5aWlvD19cXevXtx6dIlxMfHY/To0bh27VpZu0tEz2EYIarEVq5cCX9/f3z++edo2LAhunfvjoMHDyrHdHz99ddo0aIFfHx80K5dO9jY2Ej68K/Vq1fD2toabdq0wUcffYTAwECYmZnB0NCw1NscNmwYevToAT8/P3h4eODOnTsqZ0kAIDAwEA0bNoSbmxusrKywb98+GBsb4++//0atWrXQo0cPNGrUCIMHD8bjx495poSonMmEEELqIoiI1Ll27Rrs7e2xe/dudOjQQepyiOgVYRghotfGX3/9hYcPH8LZ2Rk3b97EF198gevXr+Ps2bOFBr8SUeXByzRE9Np48uQJJk2ahCZNmuCjjz6ClZUV4uPjoa+vj3Xr1sHU1FTt1KRJE6lLJ6Iy4JkRItIKDx48KHJwrb6+PmrXrl3BFRFReWEYISIiIknxMg0RERFJimGEiIiIJMUwQkRERJJiGCEiIiJJMYwQERGRpBhGiIiISFIMI0RERCSp/wNsJZPHZeFr7QAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_df.plot.bar(x='learning_rate', y='validation_accuracy', title='Validation Accuracy vs Learning Rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_learning_rate = results_df.loc[results_df['validation_accuracy'].idxmax()]['learning_rate']\n",
    "best_learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8055555555555556, Training Loss: 0.1435652744378462, Validation Loss: 0.12780253323994112, Precision: 51.0, Recall: 48.0, F1 Score: 49.45454545454545\n",
      "Accuracy: 0.8055555555555556, Training Loss: 0.14274188316957984, Validation Loss: 0.1261948744239586, Precision: 51.0, Recall: 48.0, F1 Score: 49.45454545454545\n",
      "Accuracy: 0.8148148148148148, Training Loss: 0.1426013984743416, Validation Loss: 0.12580667746403285, Precision: 51.0, Recall: 49.0, F1 Score: 49.98\n",
      "Accuracy: 0.8055555555555556, Training Loss: 0.14256690103523859, Validation Loss: 0.1256672133518186, Precision: 51.0, Recall: 50.0, F1 Score: 50.495049504950494\n",
      "Accuracy: 0.8055555555555556, Training Loss: 0.14255694614404543, Validation Loss: 0.12560621194018157, Precision: 51.0, Recall: 50.0, F1 Score: 50.495049504950494\n",
      "Accuracy: 0.8148148148148148, Training Loss: 0.1425538320212556, Validation Loss: 0.12557624141095916, Precision: 51.0, Recall: 51.0, F1 Score: 51.0\n",
      "Accuracy: 0.8055555555555556, Training Loss: 0.1425528147028856, Validation Loss: 0.12556042943630516, Precision: 51.0, Recall: 50.0, F1 Score: 50.495049504950494\n",
      "Accuracy: 0.8055555555555556, Training Loss: 0.14255247422300668, Validation Loss: 0.1255517159000329, Precision: 51.0, Recall: 50.0, F1 Score: 50.495049504950494\n",
      "Accuracy: 0.8055555555555556, Training Loss: 0.14255235868401397, Validation Loss: 0.12554678587235754, Precision: 51.0, Recall: 50.0, F1 Score: 50.495049504950494\n",
      "Accuracy: 0.8055555555555556, Training Loss: 0.1425523191623011, Validation Loss: 0.12554395210406455, Precision: 51.0, Recall: 50.0, F1 Score: 50.495049504950494\n",
      "Accuracy: 0.8055555555555556, Training Loss: 0.14255230558031073, Validation Loss: 0.1255423078760864, Precision: 51.0, Recall: 50.0, F1 Score: 50.495049504950494\n",
      "Accuracy: 0.8055555555555556, Training Loss: 0.14255230090002416, Validation Loss: 0.12554134852317167, Precision: 51.0, Recall: 50.0, F1 Score: 50.495049504950494\n",
      "Accuracy: 0.8055555555555556, Training Loss: 0.14255229928464713, Validation Loss: 0.12554078692781478, Precision: 51.0, Recall: 50.0, F1 Score: 50.495049504950494\n",
      "Accuracy: 0.8055555555555556, Training Loss: 0.142552298726586, Validation Loss: 0.12554045753727686, Precision: 51.0, Recall: 50.0, F1 Score: 50.495049504950494\n",
      "Accuracy: 0.8055555555555556, Training Loss: 0.1425522985336877, Validation Loss: 0.1255402641201116, Precision: 51.0, Recall: 50.0, F1 Score: 50.495049504950494\n",
      "Accuracy: 0.8055555555555556, Training Loss: 0.1425522984669893, Validation Loss: 0.1255401504696862, Precision: 51.0, Recall: 50.0, F1 Score: 50.495049504950494\n",
      "Accuracy: 0.8055555555555556, Training Loss: 0.14255229844392261, Validation Loss: 0.12554008366313635, Precision: 51.0, Recall: 50.0, F1 Score: 50.495049504950494\n",
      "Accuracy: 0.8055555555555556, Training Loss: 0.14255229843594444, Validation Loss: 0.12554004438343533, Precision: 51.0, Recall: 50.0, F1 Score: 50.495049504950494\n",
      "Accuracy: 0.8055555555555556, Training Loss: 0.14255229843318484, Validation Loss: 0.1255400212853061, Precision: 51.0, Recall: 50.0, F1 Score: 50.495049504950494\n",
      "Accuracy: 0.8055555555555556, Training Loss: 0.14255229843223025, Validation Loss: 0.12554000770153229, Precision: 51.0, Recall: 50.0, F1 Score: 50.495049504950494\n",
      "Accuracy: 0.8055555555555556, Training Loss: 0.14255229843190007, Validation Loss: 0.12553999971267496, Precision: 51.0, Recall: 50.0, F1 Score: 50.495049504950494\n",
      "Accuracy: 0.8055555555555556, Training Loss: 0.14255229843178582, Validation Loss: 0.12553999501415586, Precision: 51.0, Recall: 50.0, F1 Score: 50.495049504950494\n",
      "Accuracy: 0.8055555555555556, Training Loss: 0.14255229843174633, Validation Loss: 0.12553999225075144, Precision: 51.0, Recall: 50.0, F1 Score: 50.495049504950494\n",
      "Accuracy: 0.8055555555555556, Training Loss: 0.14255229843173264, Validation Loss: 0.12553999062545682, Precision: 51.0, Recall: 50.0, F1 Score: 50.495049504950494\n",
      "Accuracy: 0.8055555555555556, Training Loss: 0.1425522984317279, Validation Loss: 0.12553998966953536, Precision: 51.0, Recall: 50.0, F1 Score: 50.495049504950494\n",
      "Accuracy: 0.8055555555555556, Training Loss: 0.1425522984317263, Validation Loss: 0.12553998910730568, Precision: 51.0, Recall: 50.0, F1 Score: 50.495049504950494\n",
      "Accuracy: 0.8055555555555556, Training Loss: 0.1425522984317257, Validation Loss: 0.12553998877662703, Precision: 51.0, Recall: 50.0, F1 Score: 50.495049504950494\n",
      "Accuracy: 0.8055555555555556, Training Loss: 0.1425522984317255, Validation Loss: 0.1255399885821362, Precision: 51.0, Recall: 50.0, F1 Score: 50.495049504950494\n",
      "Accuracy: 0.8055555555555556, Training Loss: 0.14255229843172545, Validation Loss: 0.1255399884677451, Precision: 51.0, Recall: 50.0, F1 Score: 50.495049504950494\n",
      "Accuracy: 0.8055555555555556, Training Loss: 0.14255229843172543, Validation Loss: 0.12553998840046515, Precision: 51.0, Recall: 50.0, F1 Score: 50.495049504950494\n",
      "Accuracy: 0.8055555555555556, Training Loss: 0.14255229843172543, Validation Loss: 0.12553998836089397, Precision: 51.0, Recall: 50.0, F1 Score: 50.495049504950494\n",
      "Accuracy: 0.8055555555555556, Training Loss: 0.1425522984317254, Validation Loss: 0.12553998833761987, Precision: 51.0, Recall: 50.0, F1 Score: 50.495049504950494\n",
      "Accuracy: 0.8055555555555556, Training Loss: 0.14255229843172543, Validation Loss: 0.12553998832393104, Precision: 51.0, Recall: 50.0, F1 Score: 50.495049504950494\n",
      "Accuracy: 0.8055555555555556, Training Loss: 0.14255229843172543, Validation Loss: 0.12553998831587987, Precision: 51.0, Recall: 50.0, F1 Score: 50.495049504950494\n",
      "Accuracy: 0.8055555555555556, Training Loss: 0.14255229843172543, Validation Loss: 0.1255399883111445, Precision: 51.0, Recall: 50.0, F1 Score: 50.495049504950494\n",
      "Accuracy: 0.8055555555555556, Training Loss: 0.14255229843172543, Validation Loss: 0.12553998830835933, Precision: 51.0, Recall: 50.0, F1 Score: 50.495049504950494\n",
      "Accuracy: 0.8055555555555556, Training Loss: 0.14255229843172543, Validation Loss: 0.12553998830672128, Precision: 51.0, Recall: 50.0, F1 Score: 50.495049504950494\n",
      "Accuracy: 0.8055555555555556, Training Loss: 0.14255229843172543, Validation Loss: 0.12553998830575777, Precision: 51.0, Recall: 50.0, F1 Score: 50.495049504950494\n",
      "Accuracy: 0.8055555555555556, Training Loss: 0.14255229843172543, Validation Loss: 0.12553998830519114, Precision: 51.0, Recall: 50.0, F1 Score: 50.495049504950494\n",
      "Accuracy: 0.8055555555555556, Training Loss: 0.14255229843172543, Validation Loss: 0.12553998830485785, Precision: 51.0, Recall: 50.0, F1 Score: 50.495049504950494\n",
      "Accuracy: 0.8055555555555556, Training Loss: 0.14255229843172543, Validation Loss: 0.12553998830466181, Precision: 51.0, Recall: 50.0, F1 Score: 50.495049504950494\n",
      "Accuracy: 0.8055555555555556, Training Loss: 0.14255229843172543, Validation Loss: 0.12553998830454655, Precision: 51.0, Recall: 50.0, F1 Score: 50.495049504950494\n",
      "Accuracy: 0.8055555555555556, Training Loss: 0.14255229843172543, Validation Loss: 0.1255399883044787, Precision: 51.0, Recall: 50.0, F1 Score: 50.495049504950494\n",
      "Accuracy: 0.8055555555555556, Training Loss: 0.1425522984317254, Validation Loss: 0.12553998830443883, Precision: 51.0, Recall: 50.0, F1 Score: 50.495049504950494\n",
      "Accuracy: 0.8055555555555556, Training Loss: 0.14255229843172543, Validation Loss: 0.12553998830441537, Precision: 51.0, Recall: 50.0, F1 Score: 50.495049504950494\n",
      "Accuracy: 0.8055555555555556, Training Loss: 0.14255229843172543, Validation Loss: 0.12553998830440158, Precision: 51.0, Recall: 50.0, F1 Score: 50.495049504950494\n",
      "Accuracy: 0.8055555555555556, Training Loss: 0.14255229843172543, Validation Loss: 0.12553998830439347, Precision: 51.0, Recall: 50.0, F1 Score: 50.495049504950494\n",
      "Accuracy: 0.8055555555555556, Training Loss: 0.1425522984317254, Validation Loss: 0.1255399883043887, Precision: 51.0, Recall: 50.0, F1 Score: 50.495049504950494\n",
      "Accuracy: 0.8055555555555556, Training Loss: 0.14255229843172543, Validation Loss: 0.1255399883043859, Precision: 51.0, Recall: 50.0, F1 Score: 50.495049504950494\n",
      "Accuracy: 0.8055555555555556, Training Loss: 0.14255229843172543, Validation Loss: 0.1255399883043842, Precision: 51.0, Recall: 50.0, F1 Score: 50.495049504950494\n",
      "Accuracy: 0.8055555555555556, Training Loss: 0.1425522984317254, Validation Loss: 0.12553998830438326, Precision: 51.0, Recall: 50.0, F1 Score: 50.495049504950494\n",
      "Accuracy: 0.8055555555555556, Training Loss: 0.14255229843172543, Validation Loss: 0.12553998830438268, Precision: 51.0, Recall: 50.0, F1 Score: 50.495049504950494\n",
      "Accuracy: 0.8055555555555556, Training Loss: 0.14255229843172543, Validation Loss: 0.12553998830438234, Precision: 51.0, Recall: 50.0, F1 Score: 50.495049504950494\n",
      "Accuracy: 0.8055555555555556, Training Loss: 0.14255229843172543, Validation Loss: 0.12553998830438215, Precision: 51.0, Recall: 50.0, F1 Score: 50.495049504950494\n",
      "Accuracy: 0.8055555555555556, Training Loss: 0.14255229843172543, Validation Loss: 0.12553998830438204, Precision: 51.0, Recall: 50.0, F1 Score: 50.495049504950494\n",
      "Accuracy: 0.8055555555555556, Training Loss: 0.1425522984317254, Validation Loss: 0.12553998830438198, Precision: 51.0, Recall: 50.0, F1 Score: 50.495049504950494\n",
      "Accuracy: 0.8055555555555556, Training Loss: 0.14255229843172543, Validation Loss: 0.12553998830438193, Precision: 51.0, Recall: 50.0, F1 Score: 50.495049504950494\n",
      "Accuracy: 0.8055555555555556, Training Loss: 0.14255229843172543, Validation Loss: 0.1255399883043819, Precision: 51.0, Recall: 50.0, F1 Score: 50.495049504950494\n",
      "Accuracy: 0.8055555555555556, Training Loss: 0.14255229843172543, Validation Loss: 0.1255399883043819, Precision: 51.0, Recall: 50.0, F1 Score: 50.495049504950494\n",
      "Accuracy: 0.8055555555555556, Training Loss: 0.14255229843172543, Validation Loss: 0.1255399883043819, Precision: 51.0, Recall: 50.0, F1 Score: 50.495049504950494\n",
      "Accuracy: 0.8055555555555556, Training Loss: 0.14255229843172543, Validation Loss: 0.1255399883043819, Precision: 51.0, Recall: 50.0, F1 Score: 50.495049504950494\n",
      "Accuracy: 0.8055555555555556, Training Loss: 0.14255229843172543, Validation Loss: 0.1255399883043819, Precision: 51.0, Recall: 50.0, F1 Score: 50.495049504950494\n",
      "Accuracy: 0.8055555555555556, Training Loss: 0.14255229843172543, Validation Loss: 0.1255399883043819, Precision: 51.0, Recall: 50.0, F1 Score: 50.495049504950494\n",
      "Accuracy: 0.8055555555555556, Training Loss: 0.14255229843172543, Validation Loss: 0.1255399883043819, Precision: 51.0, Recall: 50.0, F1 Score: 50.495049504950494\n",
      "Accuracy: 0.8055555555555556, Training Loss: 0.14255229843172543, Validation Loss: 0.1255399883043819, Precision: 51.0, Recall: 50.0, F1 Score: 50.495049504950494\n",
      "Accuracy: 0.8055555555555556, Training Loss: 0.14255229843172543, Validation Loss: 0.1255399883043819, Precision: 51.0, Recall: 50.0, F1 Score: 50.495049504950494\n",
      "Accuracy: 0.8055555555555556, Training Loss: 0.14255229843172543, Validation Loss: 0.1255399883043819, Precision: 51.0, Recall: 50.0, F1 Score: 50.495049504950494\n",
      "Accuracy: 0.8055555555555556, Training Loss: 0.14255229843172543, Validation Loss: 0.1255399883043819, Precision: 51.0, Recall: 50.0, F1 Score: 50.495049504950494\n",
      "Accuracy: 0.8055555555555556, Training Loss: 0.14255229843172543, Validation Loss: 0.1255399883043819, Precision: 51.0, Recall: 50.0, F1 Score: 50.495049504950494\n",
      "Accuracy: 0.8055555555555556, Training Loss: 0.14255229843172543, Validation Loss: 0.1255399883043819, Precision: 51.0, Recall: 50.0, F1 Score: 50.495049504950494\n",
      "Accuracy: 0.8055555555555556, Training Loss: 0.14255229843172543, Validation Loss: 0.1255399883043819, Precision: 51.0, Recall: 50.0, F1 Score: 50.495049504950494\n",
      "Accuracy: 0.8055555555555556, Training Loss: 0.14255229843172543, Validation Loss: 0.1255399883043819, Precision: 51.0, Recall: 50.0, F1 Score: 50.495049504950494\n",
      "Accuracy: 0.8055555555555556, Training Loss: 0.14255229843172543, Validation Loss: 0.1255399883043819, Precision: 51.0, Recall: 50.0, F1 Score: 50.495049504950494\n",
      "Accuracy: 0.8055555555555556, Training Loss: 0.14255229843172543, Validation Loss: 0.1255399883043819, Precision: 51.0, Recall: 50.0, F1 Score: 50.495049504950494\n",
      "Accuracy: 0.8055555555555556, Training Loss: 0.14255229843172543, Validation Loss: 0.1255399883043819, Precision: 51.0, Recall: 50.0, F1 Score: 50.495049504950494\n",
      "Accuracy: 0.8055555555555556, Training Loss: 0.14255229843172543, Validation Loss: 0.1255399883043819, Precision: 51.0, Recall: 50.0, F1 Score: 50.495049504950494\n",
      "Accuracy: 0.8055555555555556, Training Loss: 0.14255229843172543, Validation Loss: 0.1255399883043819, Precision: 51.0, Recall: 50.0, F1 Score: 50.495049504950494\n",
      "Accuracy: 0.8055555555555556, Training Loss: 0.14255229843172543, Validation Loss: 0.1255399883043819, Precision: 51.0, Recall: 50.0, F1 Score: 50.495049504950494\n",
      "Accuracy: 0.8055555555555556, Training Loss: 0.14255229843172543, Validation Loss: 0.1255399883043819, Precision: 51.0, Recall: 50.0, F1 Score: 50.495049504950494\n",
      "Accuracy: 0.8055555555555556, Training Loss: 0.14255229843172543, Validation Loss: 0.1255399883043819, Precision: 51.0, Recall: 50.0, F1 Score: 50.495049504950494\n",
      "Accuracy: 0.8055555555555556, Training Loss: 0.14255229843172543, Validation Loss: 0.1255399883043819, Precision: 51.0, Recall: 50.0, F1 Score: 50.495049504950494\n",
      "Accuracy: 0.8055555555555556, Training Loss: 0.14255229843172543, Validation Loss: 0.1255399883043819, Precision: 51.0, Recall: 50.0, F1 Score: 50.495049504950494\n",
      "Accuracy: 0.8055555555555556, Training Loss: 0.14255229843172543, Validation Loss: 0.1255399883043819, Precision: 51.0, Recall: 50.0, F1 Score: 50.495049504950494\n",
      "Accuracy: 0.8055555555555556, Training Loss: 0.14255229843172543, Validation Loss: 0.1255399883043819, Precision: 51.0, Recall: 50.0, F1 Score: 50.495049504950494\n",
      "Accuracy: 0.8055555555555556, Training Loss: 0.14255229843172543, Validation Loss: 0.1255399883043819, Precision: 51.0, Recall: 50.0, F1 Score: 50.495049504950494\n",
      "Accuracy: 0.8055555555555556, Training Loss: 0.14255229843172543, Validation Loss: 0.1255399883043819, Precision: 51.0, Recall: 50.0, F1 Score: 50.495049504950494\n",
      "Accuracy: 0.8055555555555556, Training Loss: 0.14255229843172543, Validation Loss: 0.1255399883043819, Precision: 51.0, Recall: 50.0, F1 Score: 50.495049504950494\n",
      "Accuracy: 0.8055555555555556, Training Loss: 0.14255229843172543, Validation Loss: 0.1255399883043819, Precision: 51.0, Recall: 50.0, F1 Score: 50.495049504950494\n",
      "Accuracy: 0.8055555555555556, Training Loss: 0.14255229843172543, Validation Loss: 0.1255399883043819, Precision: 51.0, Recall: 50.0, F1 Score: 50.495049504950494\n",
      "Accuracy: 0.8055555555555556, Training Loss: 0.14255229843172543, Validation Loss: 0.1255399883043819, Precision: 51.0, Recall: 50.0, F1 Score: 50.495049504950494\n",
      "Accuracy: 0.8055555555555556, Training Loss: 0.14255229843172543, Validation Loss: 0.1255399883043819, Precision: 51.0, Recall: 50.0, F1 Score: 50.495049504950494\n",
      "Accuracy: 0.8055555555555556, Training Loss: 0.14255229843172543, Validation Loss: 0.1255399883043819, Precision: 51.0, Recall: 50.0, F1 Score: 50.495049504950494\n",
      "Accuracy: 0.8055555555555556, Training Loss: 0.14255229843172543, Validation Loss: 0.1255399883043819, Precision: 51.0, Recall: 50.0, F1 Score: 50.495049504950494\n",
      "Accuracy: 0.8055555555555556, Training Loss: 0.14255229843172543, Validation Loss: 0.1255399883043819, Precision: 51.0, Recall: 50.0, F1 Score: 50.495049504950494\n",
      "Accuracy: 0.8055555555555556, Training Loss: 0.14255229843172543, Validation Loss: 0.1255399883043819, Precision: 51.0, Recall: 50.0, F1 Score: 50.495049504950494\n",
      "Accuracy: 0.8055555555555556, Training Loss: 0.14255229843172543, Validation Loss: 0.1255399883043819, Precision: 51.0, Recall: 50.0, F1 Score: 50.495049504950494\n",
      "Accuracy: 0.8055555555555556, Training Loss: 0.14255229843172543, Validation Loss: 0.1255399883043819, Precision: 51.0, Recall: 50.0, F1 Score: 50.495049504950494\n",
      "Accuracy: 0.8055555555555556, Training Loss: 0.14255229843172543, Validation Loss: 0.1255399883043819, Precision: 51.0, Recall: 50.0, F1 Score: 50.495049504950494\n",
      "Accuracy: 0.8055555555555556, Training Loss: 0.14255229843172543, Validation Loss: 0.1255399883043819, Precision: 51.0, Recall: 50.0, F1 Score: 50.495049504950494\n",
      "Accuracy: 0.8055555555555556, Training Loss: 0.14255229843172543, Validation Loss: 0.1255399883043819, Precision: 51.0, Recall: 50.0, F1 Score: 50.495049504950494\n"
     ]
    }
   ],
   "source": [
    "learning_rate = best_learning_rate\n",
    "W = np.random.rand(6).reshape(6,1)\n",
    "epochs = 10000\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    y_pred = sigmoid(np.matmul(X_train, W))\n",
    "    train_loss = MSELoss(y_train, y_pred)\n",
    "    W = W - learning_rate * np.matmul(X_train.T, (y_pred - y_train.reshape(-1,1)) * (y_pred * (1-y_pred)))\n",
    "    \n",
    "    y_pred_val = sigmoid(np.matmul(X_test, W))\n",
    "    validation_loss = MSELoss(y_test, y_pred_val)\n",
    "    validation_accuracy = accuracy_with_thresholding(y_test, y_pred_val)\n",
    "    val_precision = precision(y_test, y_pred_val)\n",
    "    val_recall = recall(y_test, y_pred_val)\n",
    "    f1 = f1_score(y_test, y_pred_val)\n",
    "    \n",
    "    if (epoch + 1 ) % 100 == 0:\n",
    "        print(f\"Accuracy: {validation_accuracy}, Training Loss: {train_loss}, Validation Loss: {validation_loss}, Precision: {val_precision}, Recall: {val_recall}, F1 Score: {f1}\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "def save_model(weights: np.ndarray, mean: float, std: float, model_path: str):\n",
    "    \"\"\"\n",
    "    Save the model weights to a file.\n",
    "\n",
    "    Args:\n",
    "        weights (np.ndarray): The model weights to save.\n",
    "        mean (float): The mean used for normalization.\n",
    "        std (float): The standard deviation used for normalization.\n",
    "        model_path (str): The path where the model should be saved.\n",
    "    \"\"\"\n",
    "    np.save(model_path + \".npy\", weights)\n",
    "    with open(model_path + \"_meta.json\", \"w\") as f:\n",
    "        json.dump({\"mean\": mean, \"std\": std}, f)\n",
    "\n",
    "def load_model(model_path: str) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Load the model weights from a file.\n",
    "\n",
    "    Args:\n",
    "        model_path (str): The path where the model is saved.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: The loaded model weights.\n",
    "    \"\"\"\n",
    "    weights = np.load(model_path  + \".npy\")\n",
    "    with open(model_path + \"_meta.json\", \"r\") as f:\n",
    "        meta = json.load(f)\n",
    "    return weights, meta[\"mean\"], meta[\"std\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(W, mean, std, \"model_weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-1.60102386],\n",
       "        [ 2.836165  ],\n",
       "        [-0.72868274],\n",
       "        [-0.32215925],\n",
       "        [ 0.00292129],\n",
       "        [ 1.9230948 ]]),\n",
       " 29.69911764705882,\n",
       " 14.526497332334042)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W, mean, std = load_model(\"model_weights\")\n",
    "W, mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sigmoid(z):\n",
    "    return 1/(1 + np.exp(-z))\n",
    "\n",
    "X = np.array([[0, 1, 0, 0, 0, 1]])\n",
    "y_pred = (sigmoid(np.matmul(X, W)) > 0.5).astype(np.int32)[0][0]\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\AppData\\Local\\Temp\\ipykernel_17620\\3548630848.py:2: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  float(sigmoid(np.matmul(X, W)))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9915009018063856"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X = np.array([[0, 1, 0, 0, 0, 1]])\n",
    "float(sigmoid(np.matmul(X, W)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
